{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cyu_LNHkLcuQ"
      },
      "source": [
        "## Libraries & Setup"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LWJOoH8xLcuU"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.parallel\n",
        "\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD\n",
        "\n",
        "from utils.adaquant import optimize_layer_adaquant\n",
        "from utils.load_dataset import load_dataset\n",
        "from utils.utils_functions import val_loop, set_seeds\n",
        "from utils.mobilenet_v2 import MobileNetV2\n",
        "from utils.quantize import QConv2d, QLinear\n",
        "from utils.trainer import Trainer\n",
        "set_seeds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nsPl6gZlLcuW"
      },
      "outputs": [],
      "source": [
        "acc = -1\n",
        "loss = -1\n",
        "best_prec1 = 0\n",
        "dtype = torch.float32"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sjIYB-L8LcuX"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "cal_dataloader, train_dataloader, val_dataloader=load_dataset(\n",
        "'./data/calibration',\n",
        "'./data/calibration_labels.csv',\n",
        "'./data/cifar-10/train',\n",
        "'./data/cifar-10/trainLabels.csv'\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WyZ0-rUnLcua"
      },
      "source": [
        "## Model, Optimizer, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45.74574574574575"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MobileNetV2(num_bits=8, num_bits_weight=8)\n",
        "model.load_state_dict(torch.load('models/mobilenet1.pt'))\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=1e-2, momentum=0.5, weight_decay=0)\n",
        "trainer = Trainer(model, criterion, optimizer, device=torch.device(\"cpu\"))\n",
        "\n",
        "val_loop(cal_dataloader, model, 'cpu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y1QO1EtnLcuc"
      },
      "source": [
        "## Cache, Hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "llDYo3MNLcuc"
      },
      "outputs": [],
      "source": [
        "cached_qinput = {}\n",
        "\n",
        "def Qhook(name, module, input, output):\n",
        "    if module not in cached_qinput:\n",
        "        cached_qinput[module] = []\n",
        "        cached_qinput[module].append(input[0].detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_y_PDu3wLcud"
      },
      "outputs": [],
      "source": [
        "cached_input_output = {}\n",
        "\n",
        "def hook(name, module, input, output):\n",
        "    if module not in cached_input_output:\n",
        "        cached_input_output[module] = []\n",
        "    cached_input_output[module].append((input[0].detach().cpu(), output.detach().cpu()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl8zpIswLcud",
        "outputId": "c7025283-f196-4233-ac6a-f7c338988bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features.0.0\n",
            "features.1.conv.0.0\n",
            "features.1.conv.1\n",
            "features.2.conv.0.0\n",
            "features.2.conv.1.0\n",
            "features.2.conv.2\n",
            "features.3.conv.0.0\n",
            "features.3.conv.1.0\n",
            "features.3.conv.2\n",
            "features.4.conv.0.0\n",
            "features.4.conv.1.0\n",
            "features.4.conv.2\n",
            "features.5.conv.0.0\n",
            "features.5.conv.1.0\n",
            "features.5.conv.2\n",
            "features.6.conv.0.0\n",
            "features.6.conv.1.0\n",
            "features.6.conv.2\n",
            "features.7.conv.0.0\n",
            "features.7.conv.1.0\n",
            "features.7.conv.2\n",
            "features.8.conv.0.0\n",
            "features.8.conv.1.0\n",
            "features.8.conv.2\n",
            "features.9.conv.0.0\n",
            "features.9.conv.1.0\n",
            "features.9.conv.2\n",
            "features.10.conv.0.0\n",
            "features.10.conv.1.0\n",
            "features.10.conv.2\n",
            "features.11.conv.0.0\n",
            "features.11.conv.1.0\n",
            "features.11.conv.2\n",
            "features.12.conv.0.0\n",
            "features.12.conv.1.0\n",
            "features.12.conv.2\n",
            "features.13.conv.0.0\n",
            "features.13.conv.1.0\n",
            "features.13.conv.2\n",
            "features.14.conv.0.0\n",
            "features.14.conv.1.0\n",
            "features.14.conv.2\n",
            "features.15.conv.0.0\n",
            "features.15.conv.1.0\n",
            "features.15.conv.2\n",
            "features.16.conv.0.0\n",
            "features.16.conv.1.0\n",
            "features.16.conv.2\n",
            "features.17.conv.0.0\n",
            "features.17.conv.1.0\n",
            "features.17.conv.2\n",
            "features.18.0\n",
            "classifier.1\n"
          ]
        }
      ],
      "source": [
        "for name, m in model.named_modules():\n",
        "    if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "        print(name)\n",
        "        m.name = name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jQIYG_5dLcue"
      },
      "outputs": [],
      "source": [
        "handlers = []\n",
        "count = 0\n",
        "for name, m in model.named_modules():\n",
        "    if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "        m.quantize = False\n",
        "        handlers.append(m.register_forward_hook(partial(hook, name)))\n",
        "        count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GrF88RKLcuf",
        "outputId": "9c35c806-25f9-44c2-c0a0-8ea580087aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input/outputs cached\n"
          ]
        }
      ],
      "source": [
        "# Store input/output for all quantizable layers\n",
        "trainer.validate(val_dataloader)\n",
        "print(\"Input/outputs cached\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7FUABnD0Lcug"
      },
      "outputs": [],
      "source": [
        "for handler in handlers:\n",
        "    handler.remove()\n",
        "\n",
        "for m in model.modules():\n",
        "    if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "        m.quantize = True"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3FiBDSMdLcuh"
      },
      "source": [
        "## Loop Through Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AjR0_09hLcuh"
      },
      "outputs": [],
      "source": [
        "mse_df = pd.DataFrame(\n",
        "    index=np.arange(len(cached_input_output)),\n",
        "    columns=[\"name\", \"bit\", \"shape\", \"mse_before\", \"mse_after\", \"acc\"],\n",
        ")\n",
        "print_freq = 100\n",
        "evaluate = \"evaluate\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAz_Jm_aLcuh",
        "outputId": "cf98c0e9-31bc-4e01-bf1c-91c2b446cb63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optimize 0:features.0.0 for 8 bit of shape torch.Size([32, 3, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 92.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.3005015552043915\n",
            "MSE after optimization:  0.032455552369356155\n",
            "cashed quant Inputfeatures.1.conv.0.0\n",
            "\n",
            "Optimize 1:features.1.conv.0.0 for 8 bit of shape torch.Size([32, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 45.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.002374418079853058\n",
            "MSE after optimization:  0.0023612570948898792\n",
            "cashed quant Inputfeatures.1.conv.1\n",
            "\n",
            "Optimize 2:features.1.conv.1 for 8 bit of shape torch.Size([16, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 56.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.003858943236991763\n",
            "MSE after optimization:  0.0032873444724828005\n",
            "cashed quant Inputfeatures.2.conv.0.0\n",
            "\n",
            "Optimize 3:features.2.conv.0.0 for 8 bit of shape torch.Size([96, 16, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 55.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.05347907543182373\n",
            "MSE after optimization:  0.053474221378564835\n",
            "cashed quant Inputfeatures.2.conv.1.0\n",
            "\n",
            "Optimize 4:features.2.conv.1.0 for 8 bit of shape torch.Size([96, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.04491991177201271\n",
            "MSE after optimization:  0.03614884242415428\n",
            "cashed quant Inputfeatures.2.conv.2\n",
            "\n",
            "Optimize 5:features.2.conv.2 for 8 bit of shape torch.Size([24, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 60.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.08661017566919327\n",
            "MSE after optimization:  0.0783320963382721\n",
            "cashed quant Inputfeatures.3.conv.0.0\n",
            "\n",
            "Optimize 6:features.3.conv.0.0 for 8 bit of shape torch.Size([144, 24, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 86.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.08387216180562973\n",
            "MSE after optimization:  0.07656430453062057\n",
            "cashed quant Inputfeatures.3.conv.1.0\n",
            "\n",
            "Optimize 7:features.3.conv.1.0 for 8 bit of shape torch.Size([144, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 43.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.008655977435410023\n",
            "MSE after optimization:  0.0027042729780077934\n",
            "cashed quant Inputfeatures.3.conv.2\n",
            "\n",
            "Optimize 8:features.3.conv.2 for 8 bit of shape torch.Size([24, 144, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 49.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.018840037286281586\n",
            "MSE after optimization:  0.015646224841475487\n",
            "cashed quant Inputfeatures.4.conv.0.0\n",
            "\n",
            "Optimize 9:features.4.conv.0.0 for 8 bit of shape torch.Size([144, 24, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 77.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.2172471582889557\n",
            "MSE after optimization:  0.18928572535514832\n",
            "cashed quant Inputfeatures.4.conv.1.0\n",
            "\n",
            "Optimize 10:features.4.conv.1.0 for 8 bit of shape torch.Size([144, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 45.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0950741097331047\n",
            "MSE after optimization:  0.02344476990401745\n",
            "cashed quant Inputfeatures.4.conv.2\n",
            "\n",
            "Optimize 11:features.4.conv.2 for 8 bit of shape torch.Size([32, 144, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 157.33it/s]\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(cached_input_output):\n",
        "    if i > 0: \n",
        "        count = 0\n",
        "        cached_qinput = {}\n",
        "        for name, m in model.named_modules():\n",
        "            if layer.name == name:\n",
        "                if count < 5:\n",
        "                    handler = m.register_forward_hook(partial(Qhook, name))\n",
        "                    count += 1\n",
        "        trainer.validate(cal_dataloader)\n",
        "        print(\"cashed quant Input%s\" % layer.name)\n",
        "        cached_input_output[layer][0] = (\n",
        "            cached_qinput[layer][0],\n",
        "            cached_input_output[layer][0][1],\n",
        "        )\n",
        "        handler.remove()\n",
        "    print(\n",
        "        \"\\nOptimize {}:{} for {} bit of shape {}\".format(\n",
        "            i, layer.name, layer.num_bits, layer.weight.shape\n",
        "        )\n",
        "    )\n",
        "\n",
        "    mse_before, mse_after = optimize_layer_adaquant(layer, cached_input_output[layer])\n",
        "    acc=val_loop(val_dataloader, model, 'cpu')\n",
        "\n",
        "    print(\"\\nMSE before optimization: {}\".format(mse_before))\n",
        "    print(\"MSE after optimization:  {}\".format(mse_after))\n",
        "    mse_df.loc[i, \"name\"] = layer.name\n",
        "    mse_df.loc[i, \"bit\"] = layer.num_bits\n",
        "    mse_df.loc[i, \"shape\"] = str(layer.weight.shape)\n",
        "    mse_df.loc[i, \"mse_before\"] = mse_before\n",
        "    mse_df.loc[i, \"mse_after\"] = mse_after\n",
        "    mse_df.loc[i, \"acc\"] = acc\n",
        "\n",
        "\n",
        "mse_csv = evaluate + \".mse.csv\"\n",
        "mse_df.to_csv(mse_csv)\n",
        "\n",
        "filename = evaluate + \"_adaquant_val02\"\n",
        "torch.save(model.state_dict(), filename)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
