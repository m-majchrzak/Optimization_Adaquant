{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-majchrzak/Optimization_Adaquant/blob/main/main_mobilenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cyu_LNHkLcuQ"
      },
      "source": [
        "## Libraries & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Gsj6-ZzeN5_",
        "outputId": "1c92350a-64f8-4dab-8750-420d2777da39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "rm: cannot remove './Optimization_Adaquant/': No such file or directory\n",
            "Cloning into 'Optimization_Adaquant'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 128 (delta 62), reused 70 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (128/128), 6.31 MiB | 20.72 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "/content/Optimization_Adaquant\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyunpack\n",
            "  Downloading pyunpack-0.3-py2.py3-none-any.whl (4.1 kB)\n",
            "Collecting easyprocess (from pyunpack)\n",
            "  Downloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n",
            "Collecting entrypoint2 (from pyunpack)\n",
            "  Downloading entrypoint2-1.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Installing collected packages: entrypoint2, easyprocess, pyunpack\n",
            "Successfully installed easyprocess-1.1 entrypoint2-1.1 pyunpack-0.3\n"
          ]
        }
      ],
      "source": [
        "# %cd /content/\n",
        "# !rm -r ./Optimization_Adaquant/\n",
        "# !git clone https://github.com/m-majchrzak/Optimization_Adaquant.git\n",
        "# %cd Optimization_Adaquant/\n",
        "# !pip install pyunpack\n",
        "# from pyunpack import Archive\n",
        "# Archive('calibration_datasets.zip').extractall(\"\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LWJOoH8xLcuU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.parallel\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD, Adam\n",
        "\n",
        "from utils.adaquant import optimize_layer_adaquant\n",
        "from utils.load_dataset import load_dataset\n",
        "from utils.misc import set_global_seeds\n",
        "from utils.mobilenet_v2 import mobilenet_v2, MobileNetV2\n",
        "from utils.quantize import QConv2d, QLinear\n",
        "from utils.resnet import ResNet_imagenet\n",
        "from utils.trainer import Trainer\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from utils.kaggle_cifar_10_dataset import KaggleCIFAR10Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def val_loop(dataloader, model, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    n_batches = len(dataloader)\n",
        "    val_loss, score = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_imgs, batch_labels in dataloader:\n",
        "            batch_imgs, batch_labels = batch_imgs.to(device), batch_labels.to(device)\n",
        "            logits = model(batch_imgs)\n",
        "            # val_loss += loss_fn(logits, batch_labels).item()\n",
        "            score += (logits.argmax(1) == batch_labels).type(torch.float).sum().item()\n",
        "\n",
        "    # val_loss /= n_batches\n",
        "    score /= size\n",
        "    accuracy = 100 * score\n",
        "    # print(f'Validation error: \\n Accuracy: {(accuracy):>0.1f}, Avg loss: {val_loss:>8f}\\n')\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_seeds():\n",
        "    torch.manual_seed(0)\n",
        "    random.seed(0)\n",
        "    np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nsPl6gZlLcuW"
      },
      "outputs": [],
      "source": [
        "acc = -1\n",
        "loss = -1\n",
        "best_prec1 = 0\n",
        "dtype = torch.float32"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sjIYB-L8LcuX"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = KaggleCIFAR10Dataset(\n",
        "        'data/calibration_Wladek', \n",
        "        'data/calibration_labels.csv', \n",
        "         transforms.Compose([ # basic augmentation\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ColorJitter(),\n",
        "                transforms.RandomRotation(10)\n",
        "            ]))\n",
        "\n",
        "cal_dataloader, _ = dataset.get_train_val_dataloaders(\n",
        "    0.999, \n",
        "    {\n",
        "        'batch_size': 128,\n",
        "        'shuffle': False,\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = KaggleCIFAR10Dataset(\n",
        "        'cifar-10/train', \n",
        "        'cifar-10/trainLabels.csv', \n",
        "         transforms.Compose([ # basic augmentation\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ColorJitter(),\n",
        "                transforms.RandomRotation(10)\n",
        "            ]))\n",
        "\n",
        "train_dataloader, val_dataloader = dataset.get_train_val_dataloaders(\n",
        "    0.9, \n",
        "    {\n",
        "        'batch_size': 128,\n",
        "        'shuffle': True,\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MobileNetV2(num_bits=8, num_bits_weight=8)\n",
        "model.load_state_dict(torch.load('./mobilenet1.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44.84484484484484"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_loop(cal_dataloader, model, 'cpu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WyZ0-rUnLcua"
      },
      "source": [
        "## Model, Optimizer, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "### LOAD MODEL\n",
        "model = MobileNetV2(num_bits=8, num_bits_weight=8)\n",
        "model.load_state_dict(torch.load('./mobilenet1.pt'))\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=1e-2, momentum=0.5, weight_decay=0)\n",
        "trainer = Trainer(model, criterion, optimizer, device=torch.device(\"cpu\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y1QO1EtnLcuc"
      },
      "source": [
        "## Cache, Hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "llDYo3MNLcuc"
      },
      "outputs": [],
      "source": [
        "cached_qinput = {}\n",
        "\n",
        "\n",
        "def Qhook(name, module, input, output):\n",
        "    if module not in cached_qinput:\n",
        "        cached_qinput[module] = []\n",
        "        # Meanwhile store data in the RAM.\n",
        "        cached_qinput[module].append(input[0].detach().cpu())\n",
        "        # print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_y_PDu3wLcud"
      },
      "outputs": [],
      "source": [
        "cached_input_output = {}\n",
        "\n",
        "\n",
        "def hook(name, module, input, output):\n",
        "    if module not in cached_input_output:\n",
        "        cached_input_output[module] = []\n",
        "    # Meanwhile store data in the RAM.\n",
        "    cached_input_output[module].append((input[0].detach().cpu(), output.detach().cpu()))\n",
        "    # print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl8zpIswLcud",
        "outputId": "c7025283-f196-4233-ac6a-f7c338988bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features.0.0\n",
            "features.1.conv.0.0\n",
            "features.1.conv.1\n",
            "features.2.conv.0.0\n",
            "features.2.conv.1.0\n",
            "features.2.conv.2\n",
            "features.3.conv.0.0\n",
            "features.3.conv.1.0\n",
            "features.3.conv.2\n",
            "features.4.conv.0.0\n",
            "features.4.conv.1.0\n",
            "features.4.conv.2\n",
            "features.5.conv.0.0\n",
            "features.5.conv.1.0\n",
            "features.5.conv.2\n",
            "features.6.conv.0.0\n",
            "features.6.conv.1.0\n",
            "features.6.conv.2\n",
            "features.7.conv.0.0\n",
            "features.7.conv.1.0\n",
            "features.7.conv.2\n",
            "features.8.conv.0.0\n",
            "features.8.conv.1.0\n",
            "features.8.conv.2\n",
            "features.9.conv.0.0\n",
            "features.9.conv.1.0\n",
            "features.9.conv.2\n",
            "features.10.conv.0.0\n",
            "features.10.conv.1.0\n",
            "features.10.conv.2\n",
            "features.11.conv.0.0\n",
            "features.11.conv.1.0\n",
            "features.11.conv.2\n",
            "features.12.conv.0.0\n",
            "features.12.conv.1.0\n",
            "features.12.conv.2\n",
            "features.13.conv.0.0\n",
            "features.13.conv.1.0\n",
            "features.13.conv.2\n",
            "features.14.conv.0.0\n",
            "features.14.conv.1.0\n",
            "features.14.conv.2\n",
            "features.15.conv.0.0\n",
            "features.15.conv.1.0\n",
            "features.15.conv.2\n",
            "features.16.conv.0.0\n",
            "features.16.conv.1.0\n",
            "features.16.conv.2\n",
            "features.17.conv.0.0\n",
            "features.17.conv.1.0\n",
            "features.17.conv.2\n",
            "features.18.0\n",
            "classifier.1\n"
          ]
        }
      ],
      "source": [
        "for name, m in model.named_modules():\n",
        "    if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "        print(name)\n",
        "        m.name = name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jQIYG_5dLcue"
      },
      "outputs": [],
      "source": [
        "handlers = []\n",
        "count = 0\n",
        "for name, m in model.named_modules():\n",
        "    if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "        # if isinstance(m, Conv2d) or isinstance(m, Linear):\n",
        "        # if isinstance(m, QConv2d):\n",
        "        m.quantize = False\n",
        "        # if count < 10:\n",
        "        # if (isinstance(m, QConv2d) and m.groups == 1) or isinstance(m, QLinear):\n",
        "        handlers.append(m.register_forward_hook(partial(hook, name)))\n",
        "        count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GrF88RKLcuf",
        "outputId": "9c35c806-25f9-44c2-c0a0-8ea580087aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input/outputs cached\n"
          ]
        }
      ],
      "source": [
        "# Store input/output for all quantizable layers\n",
        "trainer.validate(val_dataloader)\n",
        "print(\"Input/outputs cached\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UUS3WM1TLcuf"
      },
      "outputs": [],
      "source": [
        "for handler in handlers:\n",
        "    handler.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7FUABnD0Lcug"
      },
      "outputs": [],
      "source": [
        "for m in model.modules():\n",
        "    if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "        m.quantize = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbfo-MoXLcug",
        "outputId": "540dcbf2-fdd8-4236-d8b7-92f2d2a837cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys([QConv2d(\n",
            "  3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QConv2d(\n",
            "  320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            "), QLinear(\n",
            "  in_features=1280, out_features=10, bias=True\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")])\n"
          ]
        }
      ],
      "source": [
        "print(cached_input_output.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration accuracy before quantization for 8 bits 43.94394394394394.\n",
            "Train accuracy before quantization for 8 bits 44.928985797159434.\n",
            "\n",
            "Optimize 0:features.0.0 for 8 bit of shape torch.Size([32, 3, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 99.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.2984926104545593\n",
            "MSE after optimization:  0.03186314180493355\n",
            "cashed quant Inputfeatures.1.conv.0.0\n",
            "\n",
            "Optimize 1:features.1.conv.0.0 for 8 bit of shape torch.Size([32, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 49.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0023151671048253775\n",
            "MSE after optimization:  0.0023015954066067934\n",
            "cashed quant Inputfeatures.1.conv.1\n",
            "\n",
            "Optimize 2:features.1.conv.1 for 8 bit of shape torch.Size([16, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 59.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.003042934462428093\n",
            "MSE after optimization:  0.0030279052443802357\n",
            "cashed quant Inputfeatures.2.conv.0.0\n",
            "\n",
            "Optimize 3:features.2.conv.0.0 for 8 bit of shape torch.Size([96, 16, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 59.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.05334724485874176\n",
            "MSE after optimization:  0.053344473242759705\n",
            "cashed quant Inputfeatures.2.conv.1.0\n",
            "\n",
            "Optimize 4:features.2.conv.1.0 for 8 bit of shape torch.Size([96, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 26.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.04518884792923927\n",
            "MSE after optimization:  0.03619951382279396\n",
            "cashed quant Inputfeatures.2.conv.2\n",
            "\n",
            "Optimize 5:features.2.conv.2 for 8 bit of shape torch.Size([24, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 75.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.08652263134717941\n",
            "MSE after optimization:  0.08601566404104233\n",
            "cashed quant Inputfeatures.3.conv.0.0\n",
            "\n",
            "Optimize 6:features.3.conv.0.0 for 8 bit of shape torch.Size([144, 24, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 114.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0833631381392479\n",
            "MSE after optimization:  0.07640721648931503\n",
            "cashed quant Inputfeatures.3.conv.1.0\n",
            "\n",
            "Optimize 7:features.3.conv.1.0 for 8 bit of shape torch.Size([144, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 45.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.008864736184477806\n",
            "MSE after optimization:  0.0026981637347489595\n",
            "cashed quant Inputfeatures.3.conv.2\n",
            "\n",
            "Optimize 8:features.3.conv.2 for 8 bit of shape torch.Size([24, 144, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 60.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.019017841666936874\n",
            "MSE after optimization:  0.015838008373975754\n",
            "cashed quant Inputfeatures.4.conv.0.0\n",
            "\n",
            "Optimize 9:features.4.conv.0.0 for 8 bit of shape torch.Size([144, 24, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 112.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.21579131484031677\n",
            "MSE after optimization:  0.18857242166996002\n",
            "cashed quant Inputfeatures.4.conv.1.0\n",
            "\n",
            "Optimize 10:features.4.conv.1.0 for 8 bit of shape torch.Size([144, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 59.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.09335114061832428\n",
            "MSE after optimization:  0.019403554499149323\n",
            "cashed quant Inputfeatures.4.conv.2\n",
            "\n",
            "Optimize 11:features.4.conv.2 for 8 bit of shape torch.Size([32, 144, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 190.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.4996875524520874\n",
            "MSE after optimization:  1.3632546663284302\n",
            "cashed quant Inputfeatures.5.conv.0.0\n",
            "\n",
            "Optimize 12:features.5.conv.0.0 for 8 bit of shape torch.Size([192, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 222.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.5058451890945435\n",
            "MSE after optimization:  1.3195961713790894\n",
            "cashed quant Inputfeatures.5.conv.1.0\n",
            "\n",
            "Optimize 13:features.5.conv.1.0 for 8 bit of shape torch.Size([192, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 163.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.04396836832165718\n",
            "MSE after optimization:  0.04036199674010277\n",
            "cashed quant Inputfeatures.5.conv.2\n",
            "\n",
            "Optimize 14:features.5.conv.2 for 8 bit of shape torch.Size([32, 192, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 145.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.748206377029419\n",
            "MSE after optimization:  0.6521475315093994\n",
            "cashed quant Inputfeatures.6.conv.0.0\n",
            "\n",
            "Optimize 15:features.6.conv.0.0 for 8 bit of shape torch.Size([192, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 210.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 2.0367438793182373\n",
            "MSE after optimization:  1.7033922672271729\n",
            "cashed quant Inputfeatures.6.conv.1.0\n",
            "\n",
            "Optimize 16:features.6.conv.1.0 for 8 bit of shape torch.Size([192, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 153.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.03514740243554115\n",
            "MSE after optimization:  0.03476868197321892\n",
            "cashed quant Inputfeatures.6.conv.2\n",
            "\n",
            "Optimize 17:features.6.conv.2 for 8 bit of shape torch.Size([32, 192, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 166.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.3631581962108612\n",
            "MSE after optimization:  0.3377358615398407\n",
            "cashed quant Inputfeatures.7.conv.0.0\n",
            "\n",
            "Optimize 18:features.7.conv.0.0 for 8 bit of shape torch.Size([192, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 212.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 2.3977296352386475\n",
            "MSE after optimization:  2.2141976356506348\n",
            "cashed quant Inputfeatures.7.conv.1.0\n",
            "\n",
            "Optimize 19:features.7.conv.1.0 for 8 bit of shape torch.Size([192, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 171.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.14169245958328247\n",
            "MSE after optimization:  0.07237052917480469\n",
            "cashed quant Inputfeatures.7.conv.2\n",
            "\n",
            "Optimize 20:features.7.conv.2 for 8 bit of shape torch.Size([64, 192, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 199.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.5392793416976929\n",
            "MSE after optimization:  1.3516817092895508\n",
            "cashed quant Inputfeatures.8.conv.0.0\n",
            "\n",
            "Optimize 21:features.8.conv.0.0 for 8 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 188.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 2.2554874420166016\n",
            "MSE after optimization:  2.205075740814209\n",
            "cashed quant Inputfeatures.8.conv.1.0\n",
            "\n",
            "Optimize 22:features.8.conv.1.0 for 8 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 108.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.01586340181529522\n",
            "MSE after optimization:  0.013396153226494789\n",
            "cashed quant Inputfeatures.8.conv.2\n",
            "\n",
            "Optimize 23:features.8.conv.2 for 8 bit of shape torch.Size([64, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 151.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.49918660521507263\n",
            "MSE after optimization:  0.4825405478477478\n",
            "cashed quant Inputfeatures.9.conv.0.0\n",
            "\n",
            "Optimize 24:features.9.conv.0.0 for 8 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 182.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.8336822986602783\n",
            "MSE after optimization:  1.831572413444519\n",
            "cashed quant Inputfeatures.9.conv.1.0\n",
            "\n",
            "Optimize 25:features.9.conv.1.0 for 8 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 109.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0016472545685246587\n",
            "MSE after optimization:  0.0015714577166363597\n",
            "cashed quant Inputfeatures.9.conv.2\n",
            "\n",
            "Optimize 26:features.9.conv.2 for 8 bit of shape torch.Size([64, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 169.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.03939935192465782\n",
            "MSE after optimization:  0.03865927457809448\n",
            "cashed quant Inputfeatures.10.conv.0.0\n",
            "\n",
            "Optimize 27:features.10.conv.0.0 for 8 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 192.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.8355188369750977\n",
            "MSE after optimization:  0.8292971849441528\n",
            "cashed quant Inputfeatures.10.conv.1.0\n",
            "\n",
            "Optimize 28:features.10.conv.1.0 for 8 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 108.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0014610221842303872\n",
            "MSE after optimization:  0.001266363076865673\n",
            "cashed quant Inputfeatures.10.conv.2\n",
            "\n",
            "Optimize 29:features.10.conv.2 for 8 bit of shape torch.Size([64, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 168.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.04829435423016548\n",
            "MSE after optimization:  0.03164965286850929\n",
            "cashed quant Inputfeatures.11.conv.0.0\n",
            "\n",
            "Optimize 30:features.11.conv.0.0 for 8 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 178.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 5.9760966300964355\n",
            "MSE after optimization:  5.90229606628418\n",
            "cashed quant Inputfeatures.11.conv.1.0\n",
            "\n",
            "Optimize 31:features.11.conv.1.0 for 8 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 110.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0395558662712574\n",
            "MSE after optimization:  0.03684261068701744\n",
            "cashed quant Inputfeatures.11.conv.2\n",
            "\n",
            "Optimize 32:features.11.conv.2 for 8 bit of shape torch.Size([96, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 157.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.9300011992454529\n",
            "MSE after optimization:  0.8978418707847595\n",
            "cashed quant Inputfeatures.12.conv.0.0\n",
            "\n",
            "Optimize 33:features.12.conv.0.0 for 8 bit of shape torch.Size([576, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 156.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.13814270496368408\n",
            "MSE after optimization:  0.1369040161371231\n",
            "cashed quant Inputfeatures.12.conv.1.0\n",
            "\n",
            "Optimize 34:features.12.conv.1.0 for 8 bit of shape torch.Size([576, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 80.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0007310627843253314\n",
            "MSE after optimization:  0.0004846648371312767\n",
            "cashed quant Inputfeatures.12.conv.2\n",
            "\n",
            "Optimize 35:features.12.conv.2 for 8 bit of shape torch.Size([96, 576, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 135.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0966133400797844\n",
            "MSE after optimization:  0.06765878945589066\n",
            "cashed quant Inputfeatures.13.conv.0.0\n",
            "\n",
            "Optimize 36:features.13.conv.0.0 for 8 bit of shape torch.Size([576, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 155.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.16024573147296906\n",
            "MSE after optimization:  0.15827511250972748\n",
            "cashed quant Inputfeatures.13.conv.1.0\n",
            "\n",
            "Optimize 37:features.13.conv.1.0 for 8 bit of shape torch.Size([576, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 81.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.000624207139480859\n",
            "MSE after optimization:  0.00042982163722626865\n",
            "cashed quant Inputfeatures.13.conv.2\n",
            "\n",
            "Optimize 38:features.13.conv.2 for 8 bit of shape torch.Size([96, 576, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 134.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.05885642394423485\n",
            "MSE after optimization:  0.027982788160443306\n",
            "cashed quant Inputfeatures.14.conv.0.0\n",
            "\n",
            "Optimize 39:features.14.conv.0.0 for 8 bit of shape torch.Size([576, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 154.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.2626327872276306\n",
            "MSE after optimization:  0.258184552192688\n",
            "cashed quant Inputfeatures.14.conv.1.0\n",
            "\n",
            "Optimize 40:features.14.conv.1.0 for 8 bit of shape torch.Size([576, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 87.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0032874420285224915\n",
            "MSE after optimization:  0.000450275547336787\n",
            "cashed quant Inputfeatures.14.conv.2\n",
            "\n",
            "Optimize 41:features.14.conv.2 for 8 bit of shape torch.Size([160, 576, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 144.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.157931849360466\n",
            "MSE after optimization:  0.1545306295156479\n",
            "cashed quant Inputfeatures.15.conv.0.0\n",
            "\n",
            "Optimize 42:features.15.conv.0.0 for 8 bit of shape torch.Size([960, 160, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 126.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.8006061315536499\n",
            "MSE after optimization:  0.7579165101051331\n",
            "cashed quant Inputfeatures.15.conv.1.0\n",
            "\n",
            "Optimize 43:features.15.conv.1.0 for 8 bit of shape torch.Size([960, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 67.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.00190178700722754\n",
            "MSE after optimization:  0.0017562026623636484\n",
            "cashed quant Inputfeatures.15.conv.2\n",
            "\n",
            "Optimize 44:features.15.conv.2 for 8 bit of shape torch.Size([160, 960, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 124.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.05284402519464493\n",
            "MSE after optimization:  0.028750218451023102\n",
            "cashed quant Inputfeatures.16.conv.0.0\n",
            "\n",
            "Optimize 45:features.16.conv.0.0 for 8 bit of shape torch.Size([960, 160, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 124.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 8.503741264343262\n",
            "MSE after optimization:  5.095598220825195\n",
            "cashed quant Inputfeatures.16.conv.1.0\n",
            "\n",
            "Optimize 46:features.16.conv.1.0 for 8 bit of shape torch.Size([960, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 68.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.003327091922983527\n",
            "MSE after optimization:  0.0016083052614703774\n",
            "cashed quant Inputfeatures.16.conv.2\n",
            "\n",
            "Optimize 47:features.16.conv.2 for 8 bit of shape torch.Size([160, 960, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 123.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.3660590648651123\n",
            "MSE after optimization:  0.557174563407898\n",
            "cashed quant Inputfeatures.17.conv.0.0\n",
            "\n",
            "Optimize 48:features.17.conv.0.0 for 8 bit of shape torch.Size([960, 160, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 124.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 133.92947387695312\n",
            "MSE after optimization:  105.83589935302734\n",
            "cashed quant Inputfeatures.17.conv.1.0\n",
            "\n",
            "Optimize 49:features.17.conv.1.0 for 8 bit of shape torch.Size([960, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 67.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.005209915339946747\n",
            "MSE after optimization:  0.0013692592037841678\n",
            "cashed quant Inputfeatures.17.conv.2\n",
            "\n",
            "Optimize 50:features.17.conv.2 for 8 bit of shape torch.Size([320, 960, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 56.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.1241466999053955\n",
            "MSE after optimization:  0.584609866142273\n",
            "cashed quant Inputfeatures.18.0\n",
            "\n",
            "Optimize 51:features.18.0 for 8 bit of shape torch.Size([1280, 320, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 42.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 10.46317195892334\n",
            "MSE after optimization:  10.05456829071045\n",
            "cashed quant Inputclassifier.1\n",
            "\n",
            "Optimize 52:classifier.1 for 8 bit of shape torch.Size([10, 1280])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 194.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 3357.84326171875\n",
            "MSE after optimization:  3081.07958984375\n",
            "Calibration accuracy after quantization for 8 bits 10.01001001001001.\n",
            "Train accuracy after quantization for 8 bits 9.781956391278255.\n",
            "Calibration accuracy before quantization for 16 bits 43.74374374374375.\n",
            "Train accuracy before quantization for 16 bits 45.62912582516503.\n",
            "\n",
            "Optimize 0:features.0.0 for 16 bit of shape torch.Size([32, 3, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 91.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.30688947439193726\n",
            "MSE after optimization:  0.03325648605823517\n",
            "cashed quant Inputfeatures.1.conv.0.0\n",
            "\n",
            "Optimize 1:features.1.conv.0.0 for 16 bit of shape torch.Size([32, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 45.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.002378419740125537\n",
            "MSE after optimization:  0.0023641253355890512\n",
            "cashed quant Inputfeatures.1.conv.1\n",
            "\n",
            "Optimize 2:features.1.conv.1 for 16 bit of shape torch.Size([16, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 60.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.004283393733203411\n",
            "MSE after optimization:  0.004258161410689354\n",
            "cashed quant Inputfeatures.2.conv.0.0\n",
            "\n",
            "Optimize 3:features.2.conv.0.0 for 16 bit of shape torch.Size([96, 16, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 55.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.054172541946172714\n",
            "MSE after optimization:  0.054167620837688446\n",
            "cashed quant Inputfeatures.2.conv.1.0\n",
            "\n",
            "Optimize 4:features.2.conv.1.0 for 16 bit of shape torch.Size([96, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 25.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.04506775736808777\n",
            "MSE after optimization:  0.03611450269818306\n",
            "cashed quant Inputfeatures.2.conv.2\n",
            "\n",
            "Optimize 5:features.2.conv.2 for 16 bit of shape torch.Size([24, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 71.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.08556658774614334\n",
            "MSE after optimization:  0.08477919548749924\n",
            "cashed quant Inputfeatures.3.conv.0.0\n",
            "\n",
            "Optimize 6:features.3.conv.0.0 for 16 bit of shape torch.Size([144, 24, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 107.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.08259257674217224\n",
            "MSE after optimization:  0.07584337145090103\n",
            "cashed quant Inputfeatures.3.conv.1.0\n",
            "\n",
            "Optimize 7:features.3.conv.1.0 for 16 bit of shape torch.Size([144, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 45.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.00879143737256527\n",
            "MSE after optimization:  0.002650820417329669\n",
            "cashed quant Inputfeatures.3.conv.2\n",
            "\n",
            "Optimize 8:features.3.conv.2 for 16 bit of shape torch.Size([24, 144, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 58.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.01846202462911606\n",
            "MSE after optimization:  0.01537800021469593\n",
            "cashed quant Inputfeatures.4.conv.0.0\n",
            "\n",
            "Optimize 9:features.4.conv.0.0 for 16 bit of shape torch.Size([144, 24, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 108.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.21304535865783691\n",
            "MSE after optimization:  0.18670542538166046\n",
            "cashed quant Inputfeatures.4.conv.1.0\n",
            "\n",
            "Optimize 10:features.4.conv.1.0 for 16 bit of shape torch.Size([144, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 58.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.09348934888839722\n",
            "MSE after optimization:  0.021651096642017365\n",
            "cashed quant Inputfeatures.4.conv.2\n",
            "\n",
            "Optimize 11:features.4.conv.2 for 16 bit of shape torch.Size([32, 144, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 178.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.500240445137024\n",
            "MSE after optimization:  1.3666824102401733\n",
            "cashed quant Inputfeatures.5.conv.0.0\n",
            "\n",
            "Optimize 12:features.5.conv.0.0 for 16 bit of shape torch.Size([192, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 206.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.5228556394577026\n",
            "MSE after optimization:  1.3319298028945923\n",
            "cashed quant Inputfeatures.5.conv.1.0\n",
            "\n",
            "Optimize 13:features.5.conv.1.0 for 16 bit of shape torch.Size([192, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 155.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.04442393779754639\n",
            "MSE after optimization:  0.04099470004439354\n",
            "cashed quant Inputfeatures.5.conv.2\n",
            "\n",
            "Optimize 14:features.5.conv.2 for 16 bit of shape torch.Size([32, 192, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 162.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.7455307245254517\n",
            "MSE after optimization:  0.6483004689216614\n",
            "cashed quant Inputfeatures.6.conv.0.0\n",
            "\n",
            "Optimize 15:features.6.conv.0.0 for 16 bit of shape torch.Size([192, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 207.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 2.0296096801757812\n",
            "MSE after optimization:  1.6896275281906128\n",
            "cashed quant Inputfeatures.6.conv.1.0\n",
            "\n",
            "Optimize 16:features.6.conv.1.0 for 16 bit of shape torch.Size([192, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 155.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.03562048077583313\n",
            "MSE after optimization:  0.035278838127851486\n",
            "cashed quant Inputfeatures.6.conv.2\n",
            "\n",
            "Optimize 17:features.6.conv.2 for 16 bit of shape torch.Size([32, 192, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 163.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.3629627227783203\n",
            "MSE after optimization:  0.33735641837120056\n",
            "cashed quant Inputfeatures.7.conv.0.0\n",
            "\n",
            "Optimize 18:features.7.conv.0.0 for 16 bit of shape torch.Size([192, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 203.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 2.412761688232422\n",
            "MSE after optimization:  2.225236415863037\n",
            "cashed quant Inputfeatures.7.conv.1.0\n",
            "\n",
            "Optimize 19:features.7.conv.1.0 for 16 bit of shape torch.Size([192, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 162.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.1444796770811081\n",
            "MSE after optimization:  0.07677663117647171\n",
            "cashed quant Inputfeatures.7.conv.2\n",
            "\n",
            "Optimize 20:features.7.conv.2 for 16 bit of shape torch.Size([64, 192, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 206.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.5324370861053467\n",
            "MSE after optimization:  1.3425403833389282\n",
            "cashed quant Inputfeatures.8.conv.0.0\n",
            "\n",
            "Optimize 21:features.8.conv.0.0 for 16 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 186.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 2.2249653339385986\n",
            "MSE after optimization:  2.1753475666046143\n",
            "cashed quant Inputfeatures.8.conv.1.0\n",
            "\n",
            "Optimize 22:features.8.conv.1.0 for 16 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 108.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.015582863241434097\n",
            "MSE after optimization:  0.013108450919389725\n",
            "cashed quant Inputfeatures.8.conv.2\n",
            "\n",
            "Optimize 23:features.8.conv.2 for 16 bit of shape torch.Size([64, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 153.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.5019829273223877\n",
            "MSE after optimization:  0.4866074323654175\n",
            "cashed quant Inputfeatures.9.conv.0.0\n",
            "\n",
            "Optimize 24:features.9.conv.0.0 for 16 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 185.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.8185451030731201\n",
            "MSE after optimization:  1.8164318799972534\n",
            "cashed quant Inputfeatures.9.conv.1.0\n",
            "\n",
            "Optimize 25:features.9.conv.1.0 for 16 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 107.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0016554062021896243\n",
            "MSE after optimization:  0.001578915398567915\n",
            "cashed quant Inputfeatures.9.conv.2\n",
            "\n",
            "Optimize 26:features.9.conv.2 for 16 bit of shape torch.Size([64, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 158.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.039184652268886566\n",
            "MSE after optimization:  0.038475584238767624\n",
            "cashed quant Inputfeatures.10.conv.0.0\n",
            "\n",
            "Optimize 27:features.10.conv.0.0 for 16 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 174.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.8278619050979614\n",
            "MSE after optimization:  0.8216145038604736\n",
            "cashed quant Inputfeatures.10.conv.1.0\n",
            "\n",
            "Optimize 28:features.10.conv.1.0 for 16 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 108.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.001437150640413165\n",
            "MSE after optimization:  0.0012476203264668584\n",
            "cashed quant Inputfeatures.10.conv.2\n",
            "\n",
            "Optimize 29:features.10.conv.2 for 16 bit of shape torch.Size([64, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 162.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.04780501872301102\n",
            "MSE after optimization:  0.0305231474339962\n",
            "cashed quant Inputfeatures.11.conv.0.0\n",
            "\n",
            "Optimize 30:features.11.conv.0.0 for 16 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 183.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 5.936518669128418\n",
            "MSE after optimization:  5.865442752838135\n",
            "cashed quant Inputfeatures.11.conv.1.0\n",
            "\n",
            "Optimize 31:features.11.conv.1.0 for 16 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 108.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.039062391966581345\n",
            "MSE after optimization:  0.036286137998104095\n",
            "cashed quant Inputfeatures.11.conv.2\n",
            "\n",
            "Optimize 32:features.11.conv.2 for 16 bit of shape torch.Size([96, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 154.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.9239405393600464\n",
            "MSE after optimization:  0.8927596807479858\n",
            "cashed quant Inputfeatures.12.conv.0.0\n",
            "\n",
            "Optimize 33:features.12.conv.0.0 for 16 bit of shape torch.Size([576, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 150.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.13722100853919983\n",
            "MSE after optimization:  0.13598203659057617\n",
            "cashed quant Inputfeatures.12.conv.1.0\n",
            "\n",
            "Optimize 34:features.12.conv.1.0 for 16 bit of shape torch.Size([576, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 81.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0007228347240015864\n",
            "MSE after optimization:  0.00048806500853970647\n",
            "cashed quant Inputfeatures.12.conv.2\n",
            "\n",
            "Optimize 35:features.12.conv.2 for 16 bit of shape torch.Size([96, 576, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 129.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.09585731476545334\n",
            "MSE after optimization:  0.06792259216308594\n",
            "cashed quant Inputfeatures.13.conv.0.0\n",
            "\n",
            "Optimize 36:features.13.conv.0.0 for 16 bit of shape torch.Size([576, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 152.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.15930941700935364\n",
            "MSE after optimization:  0.15736731886863708\n",
            "cashed quant Inputfeatures.13.conv.1.0\n",
            "\n",
            "Optimize 37:features.13.conv.1.0 for 16 bit of shape torch.Size([576, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 81.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0006203069351613522\n",
            "MSE after optimization:  0.00041877332841977477\n",
            "cashed quant Inputfeatures.13.conv.2\n",
            "\n",
            "Optimize 38:features.13.conv.2 for 16 bit of shape torch.Size([96, 576, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 132.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.05967211350798607\n",
            "MSE after optimization:  0.029304921627044678\n",
            "cashed quant Inputfeatures.14.conv.0.0\n",
            "\n",
            "Optimize 39:features.14.conv.0.0 for 16 bit of shape torch.Size([576, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 151.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.2607429325580597\n",
            "MSE after optimization:  0.25613853335380554\n",
            "cashed quant Inputfeatures.14.conv.1.0\n",
            "\n",
            "Optimize 40:features.14.conv.1.0 for 16 bit of shape torch.Size([576, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 85.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0032731671817600727\n",
            "MSE after optimization:  0.0005295780138112605\n",
            "cashed quant Inputfeatures.14.conv.2\n",
            "\n",
            "Optimize 41:features.14.conv.2 for 16 bit of shape torch.Size([160, 576, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 140.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.1617947816848755\n",
            "MSE after optimization:  0.1583632230758667\n",
            "cashed quant Inputfeatures.15.conv.0.0\n",
            "\n",
            "Optimize 42:features.15.conv.0.0 for 16 bit of shape torch.Size([960, 160, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 122.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.8263415694236755\n",
            "MSE after optimization:  0.7813980579376221\n",
            "cashed quant Inputfeatures.15.conv.1.0\n",
            "\n",
            "Optimize 43:features.15.conv.1.0 for 16 bit of shape torch.Size([960, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 66.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0019423860358074307\n",
            "MSE after optimization:  0.0017883158288896084\n",
            "cashed quant Inputfeatures.15.conv.2\n",
            "\n",
            "Optimize 44:features.15.conv.2 for 16 bit of shape torch.Size([160, 960, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 120.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.05304718017578125\n",
            "MSE after optimization:  0.028489775955677032\n",
            "cashed quant Inputfeatures.16.conv.0.0\n",
            "\n",
            "Optimize 45:features.16.conv.0.0 for 16 bit of shape torch.Size([960, 160, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 119.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 8.351783752441406\n",
            "MSE after optimization:  4.83101749420166\n",
            "cashed quant Inputfeatures.16.conv.1.0\n",
            "\n",
            "Optimize 46:features.16.conv.1.0 for 16 bit of shape torch.Size([960, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 67.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.003354980144649744\n",
            "MSE after optimization:  0.001665507908910513\n",
            "cashed quant Inputfeatures.16.conv.2\n",
            "\n",
            "Optimize 47:features.16.conv.2 for 16 bit of shape torch.Size([160, 960, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 117.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.386160135269165\n",
            "MSE after optimization:  0.5862509608268738\n",
            "cashed quant Inputfeatures.17.conv.0.0\n",
            "\n",
            "Optimize 48:features.17.conv.0.0 for 16 bit of shape torch.Size([960, 160, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 123.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 133.28131103515625\n",
            "MSE after optimization:  106.17035675048828\n",
            "cashed quant Inputfeatures.17.conv.1.0\n",
            "\n",
            "Optimize 49:features.17.conv.1.0 for 16 bit of shape torch.Size([960, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 67.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.005192582495510578\n",
            "MSE after optimization:  0.0014848564751446247\n",
            "cashed quant Inputfeatures.17.conv.2\n",
            "\n",
            "Optimize 50:features.17.conv.2 for 16 bit of shape torch.Size([320, 960, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 54.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.132315993309021\n",
            "MSE after optimization:  0.6111922860145569\n",
            "cashed quant Inputfeatures.18.0\n",
            "\n",
            "Optimize 51:features.18.0 for 16 bit of shape torch.Size([1280, 320, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 48.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 10.357117652893066\n",
            "MSE after optimization:  9.942380905151367\n",
            "cashed quant Inputclassifier.1\n",
            "\n",
            "Optimize 52:classifier.1 for 16 bit of shape torch.Size([10, 1280])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 187.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 3342.2685546875\n",
            "MSE after optimization:  3057.6669921875\n",
            "Calibration accuracy after quantization for 16 bits 9.90990990990991.\n",
            "Train accuracy after quantization for 16 bits 9.701940388077615.\n",
            "Calibration accuracy before quantization for 32 bits 44.44444444444444.\n",
            "Train accuracy before quantization for 32 bits 46.069213842768555.\n",
            "\n",
            "Optimize 0:features.0.0 for 32 bit of shape torch.Size([32, 3, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 97.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.2901204228401184\n",
            "MSE after optimization:  0.03194919973611832\n",
            "cashed quant Inputfeatures.1.conv.0.0\n",
            "\n",
            "Optimize 1:features.1.conv.0.0 for 32 bit of shape torch.Size([32, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 54.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.002353483345359564\n",
            "MSE after optimization:  0.0023393863812088966\n",
            "cashed quant Inputfeatures.1.conv.1\n",
            "\n",
            "Optimize 2:features.1.conv.1 for 32 bit of shape torch.Size([16, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 63.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.003870421089231968\n",
            "MSE after optimization:  0.0038495459593832493\n",
            "cashed quant Inputfeatures.2.conv.0.0\n",
            "\n",
            "Optimize 3:features.2.conv.0.0 for 32 bit of shape torch.Size([96, 16, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 56.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.05388159304857254\n",
            "MSE after optimization:  0.05387691408395767\n",
            "cashed quant Inputfeatures.2.conv.1.0\n",
            "\n",
            "Optimize 4:features.2.conv.1.0 for 32 bit of shape torch.Size([96, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 25.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.04509247839450836\n",
            "MSE after optimization:  0.0362536646425724\n",
            "cashed quant Inputfeatures.2.conv.2\n",
            "\n",
            "Optimize 5:features.2.conv.2 for 32 bit of shape torch.Size([24, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 75.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.08577434718608856\n",
            "MSE after optimization:  0.08505485951900482\n",
            "cashed quant Inputfeatures.3.conv.0.0\n",
            "\n",
            "Optimize 6:features.3.conv.0.0 for 32 bit of shape torch.Size([144, 24, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 108.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.08293136954307556\n",
            "MSE after optimization:  0.07574950903654099\n",
            "cashed quant Inputfeatures.3.conv.1.0\n",
            "\n",
            "Optimize 7:features.3.conv.1.0 for 32 bit of shape torch.Size([144, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 49.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.008901816792786121\n",
            "MSE after optimization:  0.002669342327862978\n",
            "cashed quant Inputfeatures.3.conv.2\n",
            "\n",
            "Optimize 8:features.3.conv.2 for 32 bit of shape torch.Size([24, 144, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 59.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.018773512914776802\n",
            "MSE after optimization:  0.01586257293820381\n",
            "cashed quant Inputfeatures.4.conv.0.0\n",
            "\n",
            "Optimize 9:features.4.conv.0.0 for 32 bit of shape torch.Size([144, 24, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 99.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.2163960039615631\n",
            "MSE after optimization:  0.19049617648124695\n",
            "cashed quant Inputfeatures.4.conv.1.0\n",
            "\n",
            "Optimize 10:features.4.conv.1.0 for 32 bit of shape torch.Size([144, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 60.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.09254011511802673\n",
            "MSE after optimization:  0.019393833354115486\n",
            "cashed quant Inputfeatures.4.conv.2\n",
            "\n",
            "Optimize 11:features.4.conv.2 for 32 bit of shape torch.Size([32, 144, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 183.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.4912930727005005\n",
            "MSE after optimization:  1.3565928936004639\n",
            "cashed quant Inputfeatures.5.conv.0.0\n",
            "\n",
            "Optimize 12:features.5.conv.0.0 for 32 bit of shape torch.Size([192, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 203.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.5189827680587769\n",
            "MSE after optimization:  1.3310425281524658\n",
            "cashed quant Inputfeatures.5.conv.1.0\n",
            "\n",
            "Optimize 13:features.5.conv.1.0 for 32 bit of shape torch.Size([192, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 155.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.044315047562122345\n",
            "MSE after optimization:  0.04081190004944801\n",
            "cashed quant Inputfeatures.5.conv.2\n",
            "\n",
            "Optimize 14:features.5.conv.2 for 32 bit of shape torch.Size([32, 192, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 163.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.7608321905136108\n",
            "MSE after optimization:  0.6641325950622559\n",
            "cashed quant Inputfeatures.6.conv.0.0\n",
            "\n",
            "Optimize 15:features.6.conv.0.0 for 32 bit of shape torch.Size([192, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 202.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 2.0198535919189453\n",
            "MSE after optimization:  1.6667664051055908\n",
            "cashed quant Inputfeatures.6.conv.1.0\n",
            "\n",
            "Optimize 16:features.6.conv.1.0 for 32 bit of shape torch.Size([192, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 156.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.03540024906396866\n",
            "MSE after optimization:  0.0350542776286602\n",
            "cashed quant Inputfeatures.6.conv.2\n",
            "\n",
            "Optimize 17:features.6.conv.2 for 32 bit of shape torch.Size([32, 192, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 165.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.3707505762577057\n",
            "MSE after optimization:  0.34626632928848267\n",
            "cashed quant Inputfeatures.7.conv.0.0\n",
            "\n",
            "Optimize 18:features.7.conv.0.0 for 32 bit of shape torch.Size([192, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 185.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 2.402863025665283\n",
            "MSE after optimization:  2.2181127071380615\n",
            "cashed quant Inputfeatures.7.conv.1.0\n",
            "\n",
            "Optimize 19:features.7.conv.1.0 for 32 bit of shape torch.Size([192, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 162.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.14386354386806488\n",
            "MSE after optimization:  0.0753135085105896\n",
            "cashed quant Inputfeatures.7.conv.2\n",
            "\n",
            "Optimize 20:features.7.conv.2 for 32 bit of shape torch.Size([64, 192, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 204.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.5467418432235718\n",
            "MSE after optimization:  1.354270577430725\n",
            "cashed quant Inputfeatures.8.conv.0.0\n",
            "\n",
            "Optimize 21:features.8.conv.0.0 for 32 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 180.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 2.249444007873535\n",
            "MSE after optimization:  2.199111223220825\n",
            "cashed quant Inputfeatures.8.conv.1.0\n",
            "\n",
            "Optimize 22:features.8.conv.1.0 for 32 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 108.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.015696965157985687\n",
            "MSE after optimization:  0.013194052502512932\n",
            "cashed quant Inputfeatures.8.conv.2\n",
            "\n",
            "Optimize 23:features.8.conv.2 for 32 bit of shape torch.Size([64, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 158.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.5054691433906555\n",
            "MSE after optimization:  0.4885207414627075\n",
            "cashed quant Inputfeatures.9.conv.0.0\n",
            "\n",
            "Optimize 24:features.9.conv.0.0 for 32 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 184.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.833777666091919\n",
            "MSE after optimization:  1.8315869569778442\n",
            "cashed quant Inputfeatures.9.conv.1.0\n",
            "\n",
            "Optimize 25:features.9.conv.1.0 for 32 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 107.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0016527996631339192\n",
            "MSE after optimization:  0.001579910283908248\n",
            "cashed quant Inputfeatures.9.conv.2\n",
            "\n",
            "Optimize 26:features.9.conv.2 for 32 bit of shape torch.Size([64, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 158.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.03970414772629738\n",
            "MSE after optimization:  0.039009831845760345\n",
            "cashed quant Inputfeatures.10.conv.0.0\n",
            "\n",
            "Optimize 27:features.10.conv.0.0 for 32 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 180.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.8347843289375305\n",
            "MSE after optimization:  0.8285118937492371\n",
            "cashed quant Inputfeatures.10.conv.1.0\n",
            "\n",
            "Optimize 28:features.10.conv.1.0 for 32 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 108.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0014486649306491017\n",
            "MSE after optimization:  0.0012520732125267386\n",
            "cashed quant Inputfeatures.10.conv.2\n",
            "\n",
            "Optimize 29:features.10.conv.2 for 32 bit of shape torch.Size([64, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 159.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.048595067113637924\n",
            "MSE after optimization:  0.03235112130641937\n",
            "cashed quant Inputfeatures.11.conv.0.0\n",
            "\n",
            "Optimize 30:features.11.conv.0.0 for 32 bit of shape torch.Size([384, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 184.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 5.964440822601318\n",
            "MSE after optimization:  5.8918914794921875\n",
            "cashed quant Inputfeatures.11.conv.1.0\n",
            "\n",
            "Optimize 31:features.11.conv.1.0 for 32 bit of shape torch.Size([384, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 106.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.03936275839805603\n",
            "MSE after optimization:  0.03669930249452591\n",
            "cashed quant Inputfeatures.11.conv.2\n",
            "\n",
            "Optimize 32:features.11.conv.2 for 32 bit of shape torch.Size([96, 384, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 146.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.9255399703979492\n",
            "MSE after optimization:  0.8953966498374939\n",
            "cashed quant Inputfeatures.12.conv.0.0\n",
            "\n",
            "Optimize 33:features.12.conv.0.0 for 32 bit of shape torch.Size([576, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 152.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.13717329502105713\n",
            "MSE after optimization:  0.13590744137763977\n",
            "cashed quant Inputfeatures.12.conv.1.0\n",
            "\n",
            "Optimize 34:features.12.conv.1.0 for 32 bit of shape torch.Size([576, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 81.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0007359327864833176\n",
            "MSE after optimization:  0.0004976856289431453\n",
            "cashed quant Inputfeatures.12.conv.2\n",
            "\n",
            "Optimize 35:features.12.conv.2 for 32 bit of shape torch.Size([96, 576, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 133.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.09676280617713928\n",
            "MSE after optimization:  0.06833505630493164\n",
            "cashed quant Inputfeatures.13.conv.0.0\n",
            "\n",
            "Optimize 36:features.13.conv.0.0 for 32 bit of shape torch.Size([576, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 146.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.15985387563705444\n",
            "MSE after optimization:  0.15783198177814484\n",
            "cashed quant Inputfeatures.13.conv.1.0\n",
            "\n",
            "Optimize 37:features.13.conv.1.0 for 32 bit of shape torch.Size([576, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 83.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0006164041114971042\n",
            "MSE after optimization:  0.00041172068449668586\n",
            "cashed quant Inputfeatures.13.conv.2\n",
            "\n",
            "Optimize 38:features.13.conv.2 for 32 bit of shape torch.Size([96, 576, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 130.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.05939161777496338\n",
            "MSE after optimization:  0.028730392456054688\n",
            "cashed quant Inputfeatures.14.conv.0.0\n",
            "\n",
            "Optimize 39:features.14.conv.0.0 for 32 bit of shape torch.Size([576, 96, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 143.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.26181623339653015\n",
            "MSE after optimization:  0.2572261095046997\n",
            "cashed quant Inputfeatures.14.conv.1.0\n",
            "\n",
            "Optimize 40:features.14.conv.1.0 for 32 bit of shape torch.Size([576, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 84.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0032891484443098307\n",
            "MSE after optimization:  0.0005165392067283392\n",
            "cashed quant Inputfeatures.14.conv.2\n",
            "\n",
            "Optimize 41:features.14.conv.2 for 32 bit of shape torch.Size([160, 576, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 140.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.1627979725599289\n",
            "MSE after optimization:  0.1593029946088791\n",
            "cashed quant Inputfeatures.15.conv.0.0\n",
            "\n",
            "Optimize 42:features.15.conv.0.0 for 32 bit of shape torch.Size([960, 160, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 124.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.8194661736488342\n",
            "MSE after optimization:  0.7743307948112488\n",
            "cashed quant Inputfeatures.15.conv.1.0\n",
            "\n",
            "Optimize 43:features.15.conv.1.0 for 32 bit of shape torch.Size([960, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 64.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.001909618848003447\n",
            "MSE after optimization:  0.0017647634958848357\n",
            "cashed quant Inputfeatures.15.conv.2\n",
            "\n",
            "Optimize 44:features.15.conv.2 for 32 bit of shape torch.Size([160, 960, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 120.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.05288492143154144\n",
            "MSE after optimization:  0.029153455048799515\n",
            "cashed quant Inputfeatures.16.conv.0.0\n",
            "\n",
            "Optimize 45:features.16.conv.0.0 for 32 bit of shape torch.Size([960, 160, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 123.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 8.237093925476074\n",
            "MSE after optimization:  4.799966335296631\n",
            "cashed quant Inputfeatures.16.conv.1.0\n",
            "\n",
            "Optimize 46:features.16.conv.1.0 for 32 bit of shape torch.Size([960, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 67.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.003334117354825139\n",
            "MSE after optimization:  0.0016097081825137138\n",
            "cashed quant Inputfeatures.16.conv.2\n",
            "\n",
            "Optimize 47:features.16.conv.2 for 32 bit of shape torch.Size([160, 960, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 120.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.3435715436935425\n",
            "MSE after optimization:  0.5269020199775696\n",
            "cashed quant Inputfeatures.17.conv.0.0\n",
            "\n",
            "Optimize 48:features.17.conv.0.0 for 32 bit of shape torch.Size([960, 160, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 124.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 133.89215087890625\n",
            "MSE after optimization:  105.00110626220703\n",
            "cashed quant Inputfeatures.17.conv.1.0\n",
            "\n",
            "Optimize 49:features.17.conv.1.0 for 32 bit of shape torch.Size([960, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 66.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.005365094635635614\n",
            "MSE after optimization:  0.0016107341507449746\n",
            "cashed quant Inputfeatures.17.conv.2\n",
            "\n",
            "Optimize 50:features.17.conv.2 for 32 bit of shape torch.Size([320, 960, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 56.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 1.0935533046722412\n",
            "MSE after optimization:  0.529356062412262\n",
            "cashed quant Inputfeatures.18.0\n",
            "\n",
            "Optimize 51:features.18.0 for 32 bit of shape torch.Size([1280, 320, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 48.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 10.549941062927246\n",
            "MSE after optimization:  10.134812355041504\n",
            "cashed quant Inputclassifier.1\n",
            "\n",
            "Optimize 52:classifier.1 for 32 bit of shape torch.Size([10, 1280])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 185.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 3355.57470703125\n",
            "MSE after optimization:  3075.38037109375\n",
            "Calibration accuracy after quantization for 32 bits 10.01001001001001.\n",
            "Train accuracy after quantization for 32 bits 9.721944388877777.\n"
          ]
        }
      ],
      "source": [
        "# AdaQuant loop\n",
        "bits=[8,16,32]\n",
        "\n",
        "for bit in bits:\n",
        "    acc = -1\n",
        "    loss = -1\n",
        "    best_prec1 = 0\n",
        "    dtype = torch.float32\n",
        "\n",
        "\n",
        "    #Load dataset\n",
        "    dataset = KaggleCIFAR10Dataset(\n",
        "        'data/calibration_Wladek', \n",
        "        'data/calibration_labels.csv', \n",
        "         transforms.Compose([\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ColorJitter(),\n",
        "                transforms.RandomRotation(10)\n",
        "            ]))\n",
        "\n",
        "    cal_dataloader, _ = dataset.get_train_val_dataloaders(\n",
        "        0.999, \n",
        "        {\n",
        "            'batch_size': 128,\n",
        "            'shuffle': False,\n",
        "        })    \n",
        "    \n",
        "    dataset_train = KaggleCIFAR10Dataset(\n",
        "        'cifar-10/train', \n",
        "        'cifar-10/trainLabels.csv', \n",
        "         transforms.Compose([ # basic augmentation\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ColorJitter(),\n",
        "                transforms.RandomRotation(10)\n",
        "            ]))\n",
        "\n",
        "    train_dataloader, val_dataloader = dataset_train.get_train_val_dataloaders(\n",
        "        0.9, \n",
        "        {\n",
        "            'batch_size': 128,\n",
        "            'shuffle': True,\n",
        "        })\n",
        "    \n",
        "    #model\n",
        "    model = MobileNetV2(num_bits=bit, num_bits_weight=bit)\n",
        "    model.load_state_dict(torch.load('./mobilenet1.pt'))\n",
        "    criterion = CrossEntropyLoss()\n",
        "    optimizer = SGD(model.parameters(), lr=1e-2, momentum=0.5, weight_decay=0)\n",
        "    trainer = Trainer(model, criterion, optimizer, device=torch.device(\"cpu\"))\n",
        "\n",
        "    cal_acc_before=val_loop(cal_dataloader, model, 'cpu')\n",
        "    train_acc_before=val_loop(val_dataloader, model, 'cpu')\n",
        "    print(f\"Calibration accuracy before quantization for {bit} bits {cal_acc_before}.\")\n",
        "    print(f\"Train accuracy before quantization for {bit} bits {train_acc_before}.\")\n",
        "\n",
        "    #save accuracy\n",
        "    with open(f\"./output_adaquant/acc_before_{bit}.txt\", 'w') as f:\n",
        "        f.write(\"Calibration \")\n",
        "        f.write(str(cal_acc_before))\n",
        "        f.write(\"Train \")\n",
        "        f.write(str(train_acc_before))\n",
        "\n",
        "    cached_qinput = {}\n",
        "\n",
        "\n",
        "    def Qhook(name, module, input, output):\n",
        "        if module not in cached_qinput:\n",
        "            cached_qinput[module] = []\n",
        "            # Meanwhile store data in the RAM.\n",
        "            cached_qinput[module].append(input[0].detach().cpu())\n",
        "            # print(name)\n",
        "\n",
        "    cached_input_output = {}\n",
        "\n",
        "\n",
        "    def hook(name, module, input, output):\n",
        "        if module not in cached_input_output:\n",
        "            cached_input_output[module] = []\n",
        "        # Meanwhile store data in the RAM.\n",
        "        cached_input_output[module].append((input[0].detach().cpu(), output.detach().cpu()))\n",
        "        # print(name)\n",
        "        \n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "            # print(name)\n",
        "            m.name = name\n",
        "\n",
        "    handlers = []\n",
        "    count = 0\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "            # if isinstance(m, Conv2d) or isinstance(m, Linear):\n",
        "            # if isinstance(m, QConv2d):\n",
        "            m.quantize = False\n",
        "            # if count < 10:\n",
        "            # if (isinstance(m, QConv2d) and m.groups == 1) or isinstance(m, QLinear):\n",
        "            handlers.append(m.register_forward_hook(partial(hook, name)))\n",
        "            count += 1\n",
        "\n",
        "    trainer.validate(val_dataloader)\n",
        "\n",
        "    for handler in handlers:\n",
        "        handler.remove()\n",
        "\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "            m.quantize = True\n",
        "\n",
        "    mse_df = pd.DataFrame(\n",
        "        index=np.arange(len(cached_input_output)),\n",
        "        columns=[\"name\", \"bit\", \"shape\", \"mse_before\", \"mse_after\", \"acc\"],\n",
        "    )\n",
        "    print_freq = 100\n",
        "    evaluate = \"./output_adaquant/evaluate\"\n",
        "\n",
        "    for i, layer in enumerate(cached_input_output):\n",
        "        if i > 0:  # and seq_adaquant = True\n",
        "            count = 0\n",
        "            cached_qinput = {}\n",
        "            for name, m in model.named_modules():\n",
        "                if layer.name == name:\n",
        "                    if count < 5:\n",
        "                        handler = m.register_forward_hook(partial(Qhook, name))\n",
        "                        count += 1\n",
        "            # Store input/output for all quantizable layers\n",
        "            trainer.validate(cal_dataloader)\n",
        "            print(\"cashed quant Input%s\" % layer.name)\n",
        "            cached_input_output[layer][0] = (\n",
        "                cached_qinput[layer][0],\n",
        "                cached_input_output[layer][0][1],\n",
        "            )\n",
        "            handler.remove()\n",
        "        print(\n",
        "            \"\\nOptimize {}:{} for {} bit of shape {}\".format(\n",
        "                i, layer.name, layer.num_bits, layer.weight.shape\n",
        "            )\n",
        "        )\n",
        "\n",
        "        mse_before, mse_after = optimize_layer_adaquant(layer, cached_input_output[layer])\n",
        "        acc=val_loop(val_dataloader, model, 'cpu')\n",
        "\n",
        "        print(\"\\nMSE before optimization: {}\".format(mse_before))\n",
        "        print(\"MSE after optimization:  {}\".format(mse_after))\n",
        "        mse_df.loc[i, \"name\"] = layer.name\n",
        "        mse_df.loc[i, \"bit\"] = layer.num_bits\n",
        "        mse_df.loc[i, \"shape\"] = str(layer.weight.shape)\n",
        "        mse_df.loc[i, \"mse_before\"] = mse_before\n",
        "        mse_df.loc[i, \"mse_after\"] = mse_after\n",
        "        mse_df.loc[i, \"acc\"] = acc\n",
        "\n",
        "\n",
        "    mse_csv = evaluate + f\"_mse_{bit}.csv\"\n",
        "    mse_df.to_csv(mse_csv)\n",
        "\n",
        "    filename = evaluate + f\"_adaquant_{bit}.pth\"\n",
        "    torch.save(model.state_dict(), filename)\n",
        "\n",
        "    cal_acc_after=val_loop(cal_dataloader, model, 'cpu')\n",
        "    train_acc_after=val_loop(val_dataloader, model, 'cpu')\n",
        "    print(f\"Calibration accuracy after quantization for {bit} bits {cal_acc_after}.\")\n",
        "    print(f\"Train accuracy after quantization for {bit} bits {train_acc_after}.\")\n",
        "\n",
        "    #save accuracy\n",
        "    with open(f\"./output_adaquant/acc_after_{bit}.txt\", 'w') as f:\n",
        "        f.write(\"Calibration \")\n",
        "        f.write(str(cal_acc_after))\n",
        "        f.write(\"Train \")\n",
        "        f.write(str(train_acc_after))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3FiBDSMdLcuh"
      },
      "source": [
        "## Loop Through Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AjR0_09hLcuh"
      },
      "outputs": [],
      "source": [
        "mse_df = pd.DataFrame(\n",
        "    index=np.arange(len(cached_input_output)),\n",
        "    columns=[\"name\", \"bit\", \"shape\", \"mse_before\", \"mse_after\", \"acc\"],\n",
        ")\n",
        "print_freq = 100\n",
        "evaluate = \"evaluate\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAz_Jm_aLcuh",
        "outputId": "cf98c0e9-31bc-4e01-bf1c-91c2b446cb63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optimize 0:features.0.0 for 8 bit of shape torch.Size([32, 3, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 89.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.03124196082353592\n",
            "MSE after optimization:  0.03124196082353592\n",
            "cashed quant Inputfeatures.1.conv.0.0\n",
            "\n",
            "Optimize 1:features.1.conv.0.0 for 8 bit of shape torch.Size([32, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 47.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.002414536429569125\n",
            "MSE after optimization:  0.001004559569992125\n",
            "cashed quant Inputfeatures.1.conv.1\n",
            "\n",
            "Optimize 2:features.1.conv.1 for 8 bit of shape torch.Size([16, 32, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 59.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.0026614144444465637\n",
            "MSE after optimization:  0.0026499000377953053\n",
            "cashed quant Inputfeatures.2.conv.0.0\n",
            "\n",
            "Optimize 3:features.2.conv.0.0 for 8 bit of shape torch.Size([96, 16, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 38.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.053434912115335464\n",
            "MSE after optimization:  0.05343203246593475\n",
            "cashed quant Inputfeatures.2.conv.1.0\n",
            "\n",
            "Optimize 4:features.2.conv.1.0 for 8 bit of shape torch.Size([96, 1, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 26.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE before optimization: 0.044913314282894135\n",
            "MSE after optimization:  0.03610830008983612\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m             count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[39m# Store input/output for all quantizable layers\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m trainer\u001b[39m.\u001b[39;49mvalidate(cal_dataloader)\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcashed quant Input\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m layer\u001b[39m.\u001b[39mname)\n\u001b[0;32m     13\u001b[0m cached_input_output[layer][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[0;32m     14\u001b[0m     cached_qinput[layer][\u001b[39m0\u001b[39m],\n\u001b[0;32m     15\u001b[0m     cached_input_output[layer][\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m],\n\u001b[0;32m     16\u001b[0m )\n",
            "File \u001b[1;32md:\\aga\\MO\\Optimization_Adaquant\\utils\\trainer.py:316\u001b[0m, in \u001b[0;36mTrainer.validate\u001b[1;34m(self, data_loader, average_output, duplicates, num_steps, rec)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[0;32m    315\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 316\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(data_loader, num_steps\u001b[39m=\u001b[39;49mnum_steps, duplicates\u001b[39m=\u001b[39;49mduplicates, average_output\u001b[39m=\u001b[39;49maverage_output, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,rec\u001b[39m=\u001b[39;49mrec)\n",
            "File \u001b[1;32md:\\aga\\MO\\Optimization_Adaquant\\utils\\trainer.py:252\u001b[0m, in \u001b[0;36mTrainer.forward\u001b[1;34m(self, data_loader, num_steps, training, duplicates, average_output, chunk_batch, rec)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mif\u001b[39;00m duplicates \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:  \n\u001b[0;32m    249\u001b[0m     inputs, target \u001b[39m=\u001b[39m _flatten_duplicates(inputs, target, batch_first,\n\u001b[0;32m    250\u001b[0m                                          expand_target\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m average_output)\n\u001b[1;32m--> 252\u001b[0m output, loss, grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(inputs, target,\n\u001b[0;32m    253\u001b[0m                                 training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m    254\u001b[0m                                 average_output\u001b[39m=\u001b[39;49maverage_output,\n\u001b[0;32m    255\u001b[0m                                 chunk_batch\u001b[39m=\u001b[39;49mchunk_batch)\n\u001b[0;32m    256\u001b[0m \u001b[39mif\u001b[39;00m rec:\n\u001b[0;32m    257\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
            "File \u001b[1;32md:\\aga\\MO\\Optimization_Adaquant\\utils\\trainer.py:137\u001b[0m, in \u001b[0;36mTrainer._step\u001b[1;34m(self, inputs_batch, target_batch, training, average_output, chunk_batch)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mpre_forward()\n\u001b[0;32m    136\u001b[0m \u001b[39m# compute output\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(inputs)\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m mixup \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     target \u001b[39m=\u001b[39m mixup\u001b[39m.\u001b[39mmix_target(target, output\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
            "File \u001b[1;32mc:\\Users\\pwkpi\\miniconda3\\envs\\env_inz_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1206\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1208\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1210\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
            "File \u001b[1;32md:\\aga\\MO\\Optimization_Adaquant\\utils\\mobilenet_v2.py:170\u001b[0m, in \u001b[0;36mMobileNetV2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
            "File \u001b[1;32md:\\aga\\MO\\Optimization_Adaquant\\utils\\mobilenet_v2.py:163\u001b[0m, in \u001b[0;36mMobileNetV2._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    161\u001b[0m     \u001b[39m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[39m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Cannot use \"squeeze\" as batch-size can be 1 => must use reshape with x.shape[0]\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39madaptive_avg_pool2d(x, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\pwkpi\\miniconda3\\envs\\env_inz_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1206\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1208\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1210\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
            "File \u001b[1;32mc:\\Users\\pwkpi\\miniconda3\\envs\\env_inz_test\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\pwkpi\\miniconda3\\envs\\env_inz_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1206\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1208\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1210\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
            "File \u001b[1;32mc:\\Users\\pwkpi\\miniconda3\\envs\\env_inz_test\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\pwkpi\\miniconda3\\envs\\env_inz_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1206\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1208\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1210\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
            "File \u001b[1;32md:\\aga\\MO\\Optimization_Adaquant\\utils\\quantize.py:390\u001b[0m, in \u001b[0;36mQConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    389\u001b[0m     qinput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquantize_input(\u001b[39minput\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquantize \u001b[39melse\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[1;32m--> 390\u001b[0m     qweight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquantize_weight(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mequ_scale) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquantize \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcal_params \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight\n\u001b[0;32m    391\u001b[0m     \u001b[39m#if not self.measure:\u001b[39;00m\n\u001b[0;32m    392\u001b[0m     \u001b[39m#    import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[39m#else:\u001b[39;00m\n\u001b[0;32m    394\u001b[0m     \u001b[39m#    print('measuring')    \u001b[39;00m\n\u001b[0;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasure \u001b[39mand\u001b[39;00m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mDEBUG\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m'\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\pwkpi\\miniconda3\\envs\\env_inz_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1206\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1208\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1210\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
            "File \u001b[1;32md:\\aga\\MO\\Optimization_Adaquant\\utils\\quantize.py:355\u001b[0m, in \u001b[0;36mQuantThUpdate.forward\u001b[1;34m(self, input, qparams)\u001b[0m\n\u001b[0;32m    351\u001b[0m qparams \u001b[39m=\u001b[39m QParams(\u001b[39mrange\u001b[39m\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_range,\n\u001b[0;32m    352\u001b[0m                   zero_point\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_zero_point, num_bits\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_bits)\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mper_ch_input: \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 355\u001b[0m q_input \u001b[39m=\u001b[39m quantize_with_grad(\u001b[39minput\u001b[39;49m, qparams\u001b[39m=\u001b[39;49mqparams, dequantize\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdequantize,\n\u001b[0;32m    356\u001b[0m                    stochastic\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstochastic, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n\u001b[0;32m    357\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mper_ch_input: q_input\u001b[39m=\u001b[39mq_input\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m    358\u001b[0m \u001b[39mreturn\u001b[39;00m q_input\n",
            "File \u001b[1;32md:\\aga\\MO\\Optimization_Adaquant\\utils\\quantize.py:228\u001b[0m, in \u001b[0;36mquantize_with_grad\u001b[1;34m(input, num_bits, qparams, flatten_dims, reduce_dim, dequantize, signed, stochastic, inplace)\u001b[0m\n\u001b[0;32m    226\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m    227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 228\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mclone()\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m qparams \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     \u001b[39massert\u001b[39;00m num_bits \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39meither provide qparams of num_bits to quantize\u001b[39m\u001b[39m\"\u001b[39m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(cached_input_output):\n",
        "    if i > 0:  # and seq_adaquant = True\n",
        "        count = 0\n",
        "        cached_qinput = {}\n",
        "        for name, m in model.named_modules():\n",
        "            if layer.name == name:\n",
        "                if count < 5:\n",
        "                    handler = m.register_forward_hook(partial(Qhook, name))\n",
        "                    count += 1\n",
        "        # Store input/output for all quantizable layers\n",
        "        trainer.validate(cal_dataloader)\n",
        "        print(\"cashed quant Input%s\" % layer.name)\n",
        "        cached_input_output[layer][0] = (\n",
        "            cached_qinput[layer][0],\n",
        "            cached_input_output[layer][0][1],\n",
        "        )\n",
        "        handler.remove()\n",
        "    print(\n",
        "        \"\\nOptimize {}:{} for {} bit of shape {}\".format(\n",
        "            i, layer.name, layer.num_bits, layer.weight.shape\n",
        "        )\n",
        "    )\n",
        "\n",
        "    mse_before, mse_after = optimize_layer_adaquant(layer, cached_input_output[layer])\n",
        "    acc=val_loop(val_dataloader, model, 'cpu')\n",
        "\n",
        "    print(\"\\nMSE before optimization: {}\".format(mse_before))\n",
        "    print(\"MSE after optimization:  {}\".format(mse_after))\n",
        "    mse_df.loc[i, \"name\"] = layer.name\n",
        "    mse_df.loc[i, \"bit\"] = layer.num_bits\n",
        "    mse_df.loc[i, \"shape\"] = str(layer.weight.shape)\n",
        "    mse_df.loc[i, \"mse_before\"] = mse_before\n",
        "    mse_df.loc[i, \"mse_after\"] = mse_after\n",
        "    mse_df.loc[i, \"acc\"] = acc\n",
        "\n",
        "\n",
        "mse_csv = evaluate + \".mse.csv\"\n",
        "mse_df.to_csv(mse_csv)\n",
        "\n",
        "filename = evaluate + \"_adaquant_val02\"\n",
        "torch.save(model.state_dict(), filename)\n",
        "\n",
        "cal_dataloader = None\n",
        "cached_input_output = None\n",
        "# val_results = trainer.validate(val_data.get_loader())\n",
        "# logging.info(val_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = evaluate + \"_adaquant.pth\"\n",
        "torch.save(model.state_dict(), filename)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mobilenet experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10.01001001001001"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_loop(cal_dataloader, model, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_xd = MobileNetV2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_predicted, all_labels = predict_from_dataloader(calib_data, model_xd)\n",
        "acc_xd = accuracy_score(all_labels.cpu().numpy(), all_predicted.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.071"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_xd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['features.0.0.equ_scale', 'features.0.0.quantize_input.running_zero_point', 'features.0.0.quantize_input.running_range', 'features.0.0.quantize_weight.running_zero_point', 'features.0.0.quantize_weight.running_range', 'features.1.conv.0.0.equ_scale', 'features.1.conv.0.0.quantize_input.running_zero_point', 'features.1.conv.0.0.quantize_input.running_range', 'features.1.conv.0.0.quantize_weight.running_zero_point', 'features.1.conv.0.0.quantize_weight.running_range', 'features.1.conv.1.equ_scale', 'features.1.conv.1.quantize_input.running_zero_point', 'features.1.conv.1.quantize_input.running_range', 'features.1.conv.1.quantize_weight.running_zero_point', 'features.1.conv.1.quantize_weight.running_range', 'features.2.conv.0.0.equ_scale', 'features.2.conv.0.0.quantize_input.running_zero_point', 'features.2.conv.0.0.quantize_input.running_range', 'features.2.conv.0.0.quantize_weight.running_zero_point', 'features.2.conv.0.0.quantize_weight.running_range', 'features.2.conv.1.0.equ_scale', 'features.2.conv.1.0.quantize_input.running_zero_point', 'features.2.conv.1.0.quantize_input.running_range', 'features.2.conv.1.0.quantize_weight.running_zero_point', 'features.2.conv.1.0.quantize_weight.running_range', 'features.2.conv.2.equ_scale', 'features.2.conv.2.quantize_input.running_zero_point', 'features.2.conv.2.quantize_input.running_range', 'features.2.conv.2.quantize_weight.running_zero_point', 'features.2.conv.2.quantize_weight.running_range', 'features.3.conv.0.0.equ_scale', 'features.3.conv.0.0.quantize_input.running_zero_point', 'features.3.conv.0.0.quantize_input.running_range', 'features.3.conv.0.0.quantize_weight.running_zero_point', 'features.3.conv.0.0.quantize_weight.running_range', 'features.3.conv.1.0.equ_scale', 'features.3.conv.1.0.quantize_input.running_zero_point', 'features.3.conv.1.0.quantize_input.running_range', 'features.3.conv.1.0.quantize_weight.running_zero_point', 'features.3.conv.1.0.quantize_weight.running_range', 'features.3.conv.2.equ_scale', 'features.3.conv.2.quantize_input.running_zero_point', 'features.3.conv.2.quantize_input.running_range', 'features.3.conv.2.quantize_weight.running_zero_point', 'features.3.conv.2.quantize_weight.running_range', 'features.4.conv.0.0.equ_scale', 'features.4.conv.0.0.quantize_input.running_zero_point', 'features.4.conv.0.0.quantize_input.running_range', 'features.4.conv.0.0.quantize_weight.running_zero_point', 'features.4.conv.0.0.quantize_weight.running_range', 'features.4.conv.1.0.equ_scale', 'features.4.conv.1.0.quantize_input.running_zero_point', 'features.4.conv.1.0.quantize_input.running_range', 'features.4.conv.1.0.quantize_weight.running_zero_point', 'features.4.conv.1.0.quantize_weight.running_range', 'features.4.conv.2.equ_scale', 'features.4.conv.2.quantize_input.running_zero_point', 'features.4.conv.2.quantize_input.running_range', 'features.4.conv.2.quantize_weight.running_zero_point', 'features.4.conv.2.quantize_weight.running_range', 'features.5.conv.0.0.equ_scale', 'features.5.conv.0.0.quantize_input.running_zero_point', 'features.5.conv.0.0.quantize_input.running_range', 'features.5.conv.0.0.quantize_weight.running_zero_point', 'features.5.conv.0.0.quantize_weight.running_range', 'features.5.conv.1.0.equ_scale', 'features.5.conv.1.0.quantize_input.running_zero_point', 'features.5.conv.1.0.quantize_input.running_range', 'features.5.conv.1.0.quantize_weight.running_zero_point', 'features.5.conv.1.0.quantize_weight.running_range', 'features.5.conv.2.equ_scale', 'features.5.conv.2.quantize_input.running_zero_point', 'features.5.conv.2.quantize_input.running_range', 'features.5.conv.2.quantize_weight.running_zero_point', 'features.5.conv.2.quantize_weight.running_range', 'features.6.conv.0.0.equ_scale', 'features.6.conv.0.0.quantize_input.running_zero_point', 'features.6.conv.0.0.quantize_input.running_range', 'features.6.conv.0.0.quantize_weight.running_zero_point', 'features.6.conv.0.0.quantize_weight.running_range', 'features.6.conv.1.0.equ_scale', 'features.6.conv.1.0.quantize_input.running_zero_point', 'features.6.conv.1.0.quantize_input.running_range', 'features.6.conv.1.0.quantize_weight.running_zero_point', 'features.6.conv.1.0.quantize_weight.running_range', 'features.6.conv.2.equ_scale', 'features.6.conv.2.quantize_input.running_zero_point', 'features.6.conv.2.quantize_input.running_range', 'features.6.conv.2.quantize_weight.running_zero_point', 'features.6.conv.2.quantize_weight.running_range', 'features.7.conv.0.0.equ_scale', 'features.7.conv.0.0.quantize_input.running_zero_point', 'features.7.conv.0.0.quantize_input.running_range', 'features.7.conv.0.0.quantize_weight.running_zero_point', 'features.7.conv.0.0.quantize_weight.running_range', 'features.7.conv.1.0.equ_scale', 'features.7.conv.1.0.quantize_input.running_zero_point', 'features.7.conv.1.0.quantize_input.running_range', 'features.7.conv.1.0.quantize_weight.running_zero_point', 'features.7.conv.1.0.quantize_weight.running_range', 'features.7.conv.2.equ_scale', 'features.7.conv.2.quantize_input.running_zero_point', 'features.7.conv.2.quantize_input.running_range', 'features.7.conv.2.quantize_weight.running_zero_point', 'features.7.conv.2.quantize_weight.running_range', 'features.8.conv.0.0.equ_scale', 'features.8.conv.0.0.quantize_input.running_zero_point', 'features.8.conv.0.0.quantize_input.running_range', 'features.8.conv.0.0.quantize_weight.running_zero_point', 'features.8.conv.0.0.quantize_weight.running_range', 'features.8.conv.1.0.equ_scale', 'features.8.conv.1.0.quantize_input.running_zero_point', 'features.8.conv.1.0.quantize_input.running_range', 'features.8.conv.1.0.quantize_weight.running_zero_point', 'features.8.conv.1.0.quantize_weight.running_range', 'features.8.conv.2.equ_scale', 'features.8.conv.2.quantize_input.running_zero_point', 'features.8.conv.2.quantize_input.running_range', 'features.8.conv.2.quantize_weight.running_zero_point', 'features.8.conv.2.quantize_weight.running_range', 'features.9.conv.0.0.equ_scale', 'features.9.conv.0.0.quantize_input.running_zero_point', 'features.9.conv.0.0.quantize_input.running_range', 'features.9.conv.0.0.quantize_weight.running_zero_point', 'features.9.conv.0.0.quantize_weight.running_range', 'features.9.conv.1.0.equ_scale', 'features.9.conv.1.0.quantize_input.running_zero_point', 'features.9.conv.1.0.quantize_input.running_range', 'features.9.conv.1.0.quantize_weight.running_zero_point', 'features.9.conv.1.0.quantize_weight.running_range', 'features.9.conv.2.equ_scale', 'features.9.conv.2.quantize_input.running_zero_point', 'features.9.conv.2.quantize_input.running_range', 'features.9.conv.2.quantize_weight.running_zero_point', 'features.9.conv.2.quantize_weight.running_range', 'features.10.conv.0.0.equ_scale', 'features.10.conv.0.0.quantize_input.running_zero_point', 'features.10.conv.0.0.quantize_input.running_range', 'features.10.conv.0.0.quantize_weight.running_zero_point', 'features.10.conv.0.0.quantize_weight.running_range', 'features.10.conv.1.0.equ_scale', 'features.10.conv.1.0.quantize_input.running_zero_point', 'features.10.conv.1.0.quantize_input.running_range', 'features.10.conv.1.0.quantize_weight.running_zero_point', 'features.10.conv.1.0.quantize_weight.running_range', 'features.10.conv.2.equ_scale', 'features.10.conv.2.quantize_input.running_zero_point', 'features.10.conv.2.quantize_input.running_range', 'features.10.conv.2.quantize_weight.running_zero_point', 'features.10.conv.2.quantize_weight.running_range', 'features.11.conv.0.0.equ_scale', 'features.11.conv.0.0.quantize_input.running_zero_point', 'features.11.conv.0.0.quantize_input.running_range', 'features.11.conv.0.0.quantize_weight.running_zero_point', 'features.11.conv.0.0.quantize_weight.running_range', 'features.11.conv.1.0.equ_scale', 'features.11.conv.1.0.quantize_input.running_zero_point', 'features.11.conv.1.0.quantize_input.running_range', 'features.11.conv.1.0.quantize_weight.running_zero_point', 'features.11.conv.1.0.quantize_weight.running_range', 'features.11.conv.2.equ_scale', 'features.11.conv.2.quantize_input.running_zero_point', 'features.11.conv.2.quantize_input.running_range', 'features.11.conv.2.quantize_weight.running_zero_point', 'features.11.conv.2.quantize_weight.running_range', 'features.12.conv.0.0.equ_scale', 'features.12.conv.0.0.quantize_input.running_zero_point', 'features.12.conv.0.0.quantize_input.running_range', 'features.12.conv.0.0.quantize_weight.running_zero_point', 'features.12.conv.0.0.quantize_weight.running_range', 'features.12.conv.1.0.equ_scale', 'features.12.conv.1.0.quantize_input.running_zero_point', 'features.12.conv.1.0.quantize_input.running_range', 'features.12.conv.1.0.quantize_weight.running_zero_point', 'features.12.conv.1.0.quantize_weight.running_range', 'features.12.conv.2.equ_scale', 'features.12.conv.2.quantize_input.running_zero_point', 'features.12.conv.2.quantize_input.running_range', 'features.12.conv.2.quantize_weight.running_zero_point', 'features.12.conv.2.quantize_weight.running_range', 'features.13.conv.0.0.equ_scale', 'features.13.conv.0.0.quantize_input.running_zero_point', 'features.13.conv.0.0.quantize_input.running_range', 'features.13.conv.0.0.quantize_weight.running_zero_point', 'features.13.conv.0.0.quantize_weight.running_range', 'features.13.conv.1.0.equ_scale', 'features.13.conv.1.0.quantize_input.running_zero_point', 'features.13.conv.1.0.quantize_input.running_range', 'features.13.conv.1.0.quantize_weight.running_zero_point', 'features.13.conv.1.0.quantize_weight.running_range', 'features.13.conv.2.equ_scale', 'features.13.conv.2.quantize_input.running_zero_point', 'features.13.conv.2.quantize_input.running_range', 'features.13.conv.2.quantize_weight.running_zero_point', 'features.13.conv.2.quantize_weight.running_range', 'features.14.conv.0.0.equ_scale', 'features.14.conv.0.0.quantize_input.running_zero_point', 'features.14.conv.0.0.quantize_input.running_range', 'features.14.conv.0.0.quantize_weight.running_zero_point', 'features.14.conv.0.0.quantize_weight.running_range', 'features.14.conv.1.0.equ_scale', 'features.14.conv.1.0.quantize_input.running_zero_point', 'features.14.conv.1.0.quantize_input.running_range', 'features.14.conv.1.0.quantize_weight.running_zero_point', 'features.14.conv.1.0.quantize_weight.running_range', 'features.14.conv.2.equ_scale', 'features.14.conv.2.quantize_input.running_zero_point', 'features.14.conv.2.quantize_input.running_range', 'features.14.conv.2.quantize_weight.running_zero_point', 'features.14.conv.2.quantize_weight.running_range', 'features.15.conv.0.0.equ_scale', 'features.15.conv.0.0.quantize_input.running_zero_point', 'features.15.conv.0.0.quantize_input.running_range', 'features.15.conv.0.0.quantize_weight.running_zero_point', 'features.15.conv.0.0.quantize_weight.running_range', 'features.15.conv.1.0.equ_scale', 'features.15.conv.1.0.quantize_input.running_zero_point', 'features.15.conv.1.0.quantize_input.running_range', 'features.15.conv.1.0.quantize_weight.running_zero_point', 'features.15.conv.1.0.quantize_weight.running_range', 'features.15.conv.2.equ_scale', 'features.15.conv.2.quantize_input.running_zero_point', 'features.15.conv.2.quantize_input.running_range', 'features.15.conv.2.quantize_weight.running_zero_point', 'features.15.conv.2.quantize_weight.running_range', 'features.16.conv.0.0.equ_scale', 'features.16.conv.0.0.quantize_input.running_zero_point', 'features.16.conv.0.0.quantize_input.running_range', 'features.16.conv.0.0.quantize_weight.running_zero_point', 'features.16.conv.0.0.quantize_weight.running_range', 'features.16.conv.1.0.equ_scale', 'features.16.conv.1.0.quantize_input.running_zero_point', 'features.16.conv.1.0.quantize_input.running_range', 'features.16.conv.1.0.quantize_weight.running_zero_point', 'features.16.conv.1.0.quantize_weight.running_range', 'features.16.conv.2.equ_scale', 'features.16.conv.2.quantize_input.running_zero_point', 'features.16.conv.2.quantize_input.running_range', 'features.16.conv.2.quantize_weight.running_zero_point', 'features.16.conv.2.quantize_weight.running_range', 'features.17.conv.0.0.equ_scale', 'features.17.conv.0.0.quantize_input.running_zero_point', 'features.17.conv.0.0.quantize_input.running_range', 'features.17.conv.0.0.quantize_weight.running_zero_point', 'features.17.conv.0.0.quantize_weight.running_range', 'features.17.conv.1.0.equ_scale', 'features.17.conv.1.0.quantize_input.running_zero_point', 'features.17.conv.1.0.quantize_input.running_range', 'features.17.conv.1.0.quantize_weight.running_zero_point', 'features.17.conv.1.0.quantize_weight.running_range', 'features.17.conv.2.equ_scale', 'features.17.conv.2.quantize_input.running_zero_point', 'features.17.conv.2.quantize_input.running_range', 'features.17.conv.2.quantize_weight.running_zero_point', 'features.17.conv.2.quantize_weight.running_range', 'features.18.0.equ_scale', 'features.18.0.quantize_input.running_zero_point', 'features.18.0.quantize_input.running_range', 'features.18.0.quantize_weight.running_zero_point', 'features.18.0.quantize_weight.running_range', 'classifier.1.equ_scale', 'classifier.1.quantize_input.running_zero_point', 'classifier.1.quantize_input.running_range', 'classifier.1.quantize_weight.running_zero_point', 'classifier.1.quantize_weight.running_range'], unexpected_keys=[])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_xd.load_state_dict(model.state_dict(), strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_predicted, all_labels = predict_from_dataloader(calib_data, model_xd)\n",
        "acc_xd_after = accuracy_score(all_labels.cpu().numpy(), all_predicted.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_xd_after"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model_xd.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "213\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "for name, m in model.named_modules():\n",
        "    i += 1\n",
        "    # print(name)\n",
        "    if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "        print(name)\n",
        "        # m.name = name\n",
        "        # # print(m.name)\n",
        "print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features.0.0\n",
            "features.1.conv.0.0\n",
            "features.1.conv.1\n",
            "features.2.conv.0.0\n",
            "features.2.conv.1.0\n",
            "features.2.conv.2\n",
            "features.3.conv.0.0\n",
            "features.3.conv.1.0\n",
            "features.3.conv.2\n",
            "features.4.conv.0.0\n",
            "features.4.conv.1.0\n",
            "features.4.conv.2\n",
            "features.5.conv.0.0\n",
            "features.5.conv.1.0\n",
            "features.5.conv.2\n",
            "features.6.conv.0.0\n",
            "features.6.conv.1.0\n",
            "features.6.conv.2\n",
            "features.7.conv.0.0\n",
            "features.7.conv.1.0\n",
            "features.7.conv.2\n",
            "features.8.conv.0.0\n",
            "features.8.conv.1.0\n",
            "features.8.conv.2\n",
            "features.9.conv.0.0\n",
            "features.9.conv.1.0\n",
            "features.9.conv.2\n",
            "features.10.conv.0.0\n",
            "features.10.conv.1.0\n",
            "features.10.conv.2\n",
            "features.11.conv.0.0\n",
            "features.11.conv.1.0\n",
            "features.11.conv.2\n",
            "features.12.conv.0.0\n",
            "features.12.conv.1.0\n",
            "features.12.conv.2\n",
            "features.13.conv.0.0\n",
            "features.13.conv.1.0\n",
            "features.13.conv.2\n",
            "features.14.conv.0.0\n",
            "features.14.conv.1.0\n",
            "features.14.conv.2\n",
            "features.15.conv.0.0\n",
            "features.15.conv.1.0\n",
            "features.15.conv.2\n",
            "features.16.conv.0.0\n",
            "features.16.conv.1.0\n",
            "features.16.conv.2\n",
            "features.17.conv.0.0\n",
            "features.17.conv.1.0\n",
            "features.17.conv.2\n",
            "features.18.0\n",
            "classifier.1\n",
            "319\n"
          ]
        }
      ],
      "source": [
        "j = 0\n",
        "for name, m in model_xd.named_modules():\n",
        "    # print(name)\n",
        "    j += 1\n",
        "    if isinstance(m, QConv2d) or isinstance(m, QLinear):\n",
        "        print(name)\n",
        "    #     m.name = name\n",
        "    #     # print(m.name)\n",
        "print(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.features[1].conv[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QuantThUpdate()"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_xd.features[1].conv[0][0].quantize_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features.0.0.weight torch.Size([32, 3, 3, 3])\n",
            "features.0.1.weight torch.Size([32])\n",
            "features.0.1.bias torch.Size([32])\n",
            "features.1.conv.0.0.weight torch.Size([32, 1, 3, 3])\n",
            "features.1.conv.0.1.weight torch.Size([32])\n",
            "features.1.conv.0.1.bias torch.Size([32])\n",
            "features.1.conv.1.weight torch.Size([16, 32, 1, 1])\n",
            "features.1.conv.2.weight torch.Size([16])\n",
            "features.1.conv.2.bias torch.Size([16])\n",
            "features.2.conv.0.0.weight torch.Size([96, 16, 1, 1])\n",
            "features.2.conv.0.1.weight torch.Size([96])\n",
            "features.2.conv.0.1.bias torch.Size([96])\n",
            "features.2.conv.1.0.weight torch.Size([96, 1, 3, 3])\n",
            "features.2.conv.1.1.weight torch.Size([96])\n",
            "features.2.conv.1.1.bias torch.Size([96])\n",
            "features.2.conv.2.weight torch.Size([24, 96, 1, 1])\n",
            "features.2.conv.3.weight torch.Size([24])\n",
            "features.2.conv.3.bias torch.Size([24])\n",
            "features.3.conv.0.0.weight torch.Size([144, 24, 1, 1])\n",
            "features.3.conv.0.1.weight torch.Size([144])\n",
            "features.3.conv.0.1.bias torch.Size([144])\n",
            "features.3.conv.1.0.weight torch.Size([144, 1, 3, 3])\n",
            "features.3.conv.1.1.weight torch.Size([144])\n",
            "features.3.conv.1.1.bias torch.Size([144])\n",
            "features.3.conv.2.weight torch.Size([24, 144, 1, 1])\n",
            "features.3.conv.3.weight torch.Size([24])\n",
            "features.3.conv.3.bias torch.Size([24])\n",
            "features.4.conv.0.0.weight torch.Size([144, 24, 1, 1])\n",
            "features.4.conv.0.1.weight torch.Size([144])\n",
            "features.4.conv.0.1.bias torch.Size([144])\n",
            "features.4.conv.1.0.weight torch.Size([144, 1, 3, 3])\n",
            "features.4.conv.1.1.weight torch.Size([144])\n",
            "features.4.conv.1.1.bias torch.Size([144])\n",
            "features.4.conv.2.weight torch.Size([32, 144, 1, 1])\n",
            "features.4.conv.3.weight torch.Size([32])\n",
            "features.4.conv.3.bias torch.Size([32])\n",
            "features.5.conv.0.0.weight torch.Size([192, 32, 1, 1])\n",
            "features.5.conv.0.1.weight torch.Size([192])\n",
            "features.5.conv.0.1.bias torch.Size([192])\n",
            "features.5.conv.1.0.weight torch.Size([192, 1, 3, 3])\n",
            "features.5.conv.1.1.weight torch.Size([192])\n",
            "features.5.conv.1.1.bias torch.Size([192])\n",
            "features.5.conv.2.weight torch.Size([32, 192, 1, 1])\n",
            "features.5.conv.3.weight torch.Size([32])\n",
            "features.5.conv.3.bias torch.Size([32])\n",
            "features.6.conv.0.0.weight torch.Size([192, 32, 1, 1])\n",
            "features.6.conv.0.1.weight torch.Size([192])\n",
            "features.6.conv.0.1.bias torch.Size([192])\n",
            "features.6.conv.1.0.weight torch.Size([192, 1, 3, 3])\n",
            "features.6.conv.1.1.weight torch.Size([192])\n",
            "features.6.conv.1.1.bias torch.Size([192])\n",
            "features.6.conv.2.weight torch.Size([32, 192, 1, 1])\n",
            "features.6.conv.3.weight torch.Size([32])\n",
            "features.6.conv.3.bias torch.Size([32])\n",
            "features.7.conv.0.0.weight torch.Size([192, 32, 1, 1])\n",
            "features.7.conv.0.1.weight torch.Size([192])\n",
            "features.7.conv.0.1.bias torch.Size([192])\n",
            "features.7.conv.1.0.weight torch.Size([192, 1, 3, 3])\n",
            "features.7.conv.1.1.weight torch.Size([192])\n",
            "features.7.conv.1.1.bias torch.Size([192])\n",
            "features.7.conv.2.weight torch.Size([64, 192, 1, 1])\n",
            "features.7.conv.3.weight torch.Size([64])\n",
            "features.7.conv.3.bias torch.Size([64])\n",
            "features.8.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
            "features.8.conv.0.1.weight torch.Size([384])\n",
            "features.8.conv.0.1.bias torch.Size([384])\n",
            "features.8.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
            "features.8.conv.1.1.weight torch.Size([384])\n",
            "features.8.conv.1.1.bias torch.Size([384])\n",
            "features.8.conv.2.weight torch.Size([64, 384, 1, 1])\n",
            "features.8.conv.3.weight torch.Size([64])\n",
            "features.8.conv.3.bias torch.Size([64])\n",
            "features.9.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
            "features.9.conv.0.1.weight torch.Size([384])\n",
            "features.9.conv.0.1.bias torch.Size([384])\n",
            "features.9.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
            "features.9.conv.1.1.weight torch.Size([384])\n",
            "features.9.conv.1.1.bias torch.Size([384])\n",
            "features.9.conv.2.weight torch.Size([64, 384, 1, 1])\n",
            "features.9.conv.3.weight torch.Size([64])\n",
            "features.9.conv.3.bias torch.Size([64])\n",
            "features.10.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
            "features.10.conv.0.1.weight torch.Size([384])\n",
            "features.10.conv.0.1.bias torch.Size([384])\n",
            "features.10.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
            "features.10.conv.1.1.weight torch.Size([384])\n",
            "features.10.conv.1.1.bias torch.Size([384])\n",
            "features.10.conv.2.weight torch.Size([64, 384, 1, 1])\n",
            "features.10.conv.3.weight torch.Size([64])\n",
            "features.10.conv.3.bias torch.Size([64])\n",
            "features.11.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
            "features.11.conv.0.1.weight torch.Size([384])\n",
            "features.11.conv.0.1.bias torch.Size([384])\n",
            "features.11.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
            "features.11.conv.1.1.weight torch.Size([384])\n",
            "features.11.conv.1.1.bias torch.Size([384])\n",
            "features.11.conv.2.weight torch.Size([96, 384, 1, 1])\n",
            "features.11.conv.3.weight torch.Size([96])\n",
            "features.11.conv.3.bias torch.Size([96])\n",
            "features.12.conv.0.0.weight torch.Size([576, 96, 1, 1])\n",
            "features.12.conv.0.1.weight torch.Size([576])\n",
            "features.12.conv.0.1.bias torch.Size([576])\n",
            "features.12.conv.1.0.weight torch.Size([576, 1, 3, 3])\n",
            "features.12.conv.1.1.weight torch.Size([576])\n",
            "features.12.conv.1.1.bias torch.Size([576])\n",
            "features.12.conv.2.weight torch.Size([96, 576, 1, 1])\n",
            "features.12.conv.3.weight torch.Size([96])\n",
            "features.12.conv.3.bias torch.Size([96])\n",
            "features.13.conv.0.0.weight torch.Size([576, 96, 1, 1])\n",
            "features.13.conv.0.1.weight torch.Size([576])\n",
            "features.13.conv.0.1.bias torch.Size([576])\n",
            "features.13.conv.1.0.weight torch.Size([576, 1, 3, 3])\n",
            "features.13.conv.1.1.weight torch.Size([576])\n",
            "features.13.conv.1.1.bias torch.Size([576])\n",
            "features.13.conv.2.weight torch.Size([96, 576, 1, 1])\n",
            "features.13.conv.3.weight torch.Size([96])\n",
            "features.13.conv.3.bias torch.Size([96])\n",
            "features.14.conv.0.0.weight torch.Size([576, 96, 1, 1])\n",
            "features.14.conv.0.1.weight torch.Size([576])\n",
            "features.14.conv.0.1.bias torch.Size([576])\n",
            "features.14.conv.1.0.weight torch.Size([576, 1, 3, 3])\n",
            "features.14.conv.1.1.weight torch.Size([576])\n",
            "features.14.conv.1.1.bias torch.Size([576])\n",
            "features.14.conv.2.weight torch.Size([160, 576, 1, 1])\n",
            "features.14.conv.3.weight torch.Size([160])\n",
            "features.14.conv.3.bias torch.Size([160])\n",
            "features.15.conv.0.0.weight torch.Size([960, 160, 1, 1])\n",
            "features.15.conv.0.1.weight torch.Size([960])\n",
            "features.15.conv.0.1.bias torch.Size([960])\n",
            "features.15.conv.1.0.weight torch.Size([960, 1, 3, 3])\n",
            "features.15.conv.1.1.weight torch.Size([960])\n",
            "features.15.conv.1.1.bias torch.Size([960])\n",
            "features.15.conv.2.weight torch.Size([160, 960, 1, 1])\n",
            "features.15.conv.3.weight torch.Size([160])\n",
            "features.15.conv.3.bias torch.Size([160])\n",
            "features.16.conv.0.0.weight torch.Size([960, 160, 1, 1])\n",
            "features.16.conv.0.1.weight torch.Size([960])\n",
            "features.16.conv.0.1.bias torch.Size([960])\n",
            "features.16.conv.1.0.weight torch.Size([960, 1, 3, 3])\n",
            "features.16.conv.1.1.weight torch.Size([960])\n",
            "features.16.conv.1.1.bias torch.Size([960])\n",
            "features.16.conv.2.weight torch.Size([160, 960, 1, 1])\n",
            "features.16.conv.3.weight torch.Size([160])\n",
            "features.16.conv.3.bias torch.Size([160])\n",
            "features.17.conv.0.0.weight torch.Size([960, 160, 1, 1])\n",
            "features.17.conv.0.1.weight torch.Size([960])\n",
            "features.17.conv.0.1.bias torch.Size([960])\n",
            "features.17.conv.1.0.weight torch.Size([960, 1, 3, 3])\n",
            "features.17.conv.1.1.weight torch.Size([960])\n",
            "features.17.conv.1.1.bias torch.Size([960])\n",
            "features.17.conv.2.weight torch.Size([320, 960, 1, 1])\n",
            "features.17.conv.3.weight torch.Size([320])\n",
            "features.17.conv.3.bias torch.Size([320])\n",
            "features.18.0.weight torch.Size([1280, 320, 1, 1])\n",
            "features.18.1.weight torch.Size([1280])\n",
            "features.18.1.bias torch.Size([1280])\n",
            "classifier.1.weight torch.Size([10, 1280])\n",
            "classifier.1.bias torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features.0.0.weight torch.Size([32, 3, 3, 3])\n",
            "features.0.0.equ_scale torch.Size([32, 1, 1, 1])\n",
            "features.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.0.0.quantize_weight.running_zero_point torch.Size([32, 1, 1, 1])\n",
            "features.0.0.quantize_weight.running_range torch.Size([32, 1, 1, 1])\n",
            "features.0.1.weight torch.Size([32])\n",
            "features.0.1.bias torch.Size([32])\n",
            "features.1.conv.0.0.weight torch.Size([32, 1, 3, 3])\n",
            "features.1.conv.0.0.equ_scale torch.Size([32, 1, 1, 1])\n",
            "features.1.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.1.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.1.conv.0.0.quantize_weight.running_zero_point torch.Size([32, 1, 1, 1])\n",
            "features.1.conv.0.0.quantize_weight.running_range torch.Size([32, 1, 1, 1])\n",
            "features.1.conv.0.1.weight torch.Size([32])\n",
            "features.1.conv.0.1.bias torch.Size([32])\n",
            "features.1.conv.1.weight torch.Size([16, 32, 1, 1])\n",
            "features.1.conv.1.equ_scale torch.Size([16, 1, 1, 1])\n",
            "features.1.conv.1.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.1.conv.1.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.1.conv.1.quantize_weight.running_zero_point torch.Size([16, 1, 1, 1])\n",
            "features.1.conv.1.quantize_weight.running_range torch.Size([16, 1, 1, 1])\n",
            "features.1.conv.2.weight torch.Size([16])\n",
            "features.1.conv.2.bias torch.Size([16])\n",
            "features.2.conv.0.0.weight torch.Size([96, 16, 1, 1])\n",
            "features.2.conv.0.0.equ_scale torch.Size([96, 1, 1, 1])\n",
            "features.2.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.2.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.2.conv.0.0.quantize_weight.running_zero_point torch.Size([96, 1, 1, 1])\n",
            "features.2.conv.0.0.quantize_weight.running_range torch.Size([96, 1, 1, 1])\n",
            "features.2.conv.0.1.weight torch.Size([96])\n",
            "features.2.conv.0.1.bias torch.Size([96])\n",
            "features.2.conv.1.0.weight torch.Size([96, 1, 3, 3])\n",
            "features.2.conv.1.0.equ_scale torch.Size([96, 1, 1, 1])\n",
            "features.2.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.2.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.2.conv.1.0.quantize_weight.running_zero_point torch.Size([96, 1, 1, 1])\n",
            "features.2.conv.1.0.quantize_weight.running_range torch.Size([96, 1, 1, 1])\n",
            "features.2.conv.1.1.weight torch.Size([96])\n",
            "features.2.conv.1.1.bias torch.Size([96])\n",
            "features.2.conv.2.weight torch.Size([24, 96, 1, 1])\n",
            "features.2.conv.2.equ_scale torch.Size([24, 1, 1, 1])\n",
            "features.2.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.2.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.2.conv.2.quantize_weight.running_zero_point torch.Size([24, 1, 1, 1])\n",
            "features.2.conv.2.quantize_weight.running_range torch.Size([24, 1, 1, 1])\n",
            "features.2.conv.3.weight torch.Size([24])\n",
            "features.2.conv.3.bias torch.Size([24])\n",
            "features.3.conv.0.0.weight torch.Size([144, 24, 1, 1])\n",
            "features.3.conv.0.0.equ_scale torch.Size([144, 1, 1, 1])\n",
            "features.3.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.3.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.3.conv.0.0.quantize_weight.running_zero_point torch.Size([144, 1, 1, 1])\n",
            "features.3.conv.0.0.quantize_weight.running_range torch.Size([144, 1, 1, 1])\n",
            "features.3.conv.0.1.weight torch.Size([144])\n",
            "features.3.conv.0.1.bias torch.Size([144])\n",
            "features.3.conv.1.0.weight torch.Size([144, 1, 3, 3])\n",
            "features.3.conv.1.0.equ_scale torch.Size([144, 1, 1, 1])\n",
            "features.3.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.3.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.3.conv.1.0.quantize_weight.running_zero_point torch.Size([144, 1, 1, 1])\n",
            "features.3.conv.1.0.quantize_weight.running_range torch.Size([144, 1, 1, 1])\n",
            "features.3.conv.1.1.weight torch.Size([144])\n",
            "features.3.conv.1.1.bias torch.Size([144])\n",
            "features.3.conv.2.weight torch.Size([24, 144, 1, 1])\n",
            "features.3.conv.2.equ_scale torch.Size([24, 1, 1, 1])\n",
            "features.3.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.3.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.3.conv.2.quantize_weight.running_zero_point torch.Size([24, 1, 1, 1])\n",
            "features.3.conv.2.quantize_weight.running_range torch.Size([24, 1, 1, 1])\n",
            "features.3.conv.3.weight torch.Size([24])\n",
            "features.3.conv.3.bias torch.Size([24])\n",
            "features.4.conv.0.0.weight torch.Size([144, 24, 1, 1])\n",
            "features.4.conv.0.0.equ_scale torch.Size([144, 1, 1, 1])\n",
            "features.4.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.4.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.4.conv.0.0.quantize_weight.running_zero_point torch.Size([144, 1, 1, 1])\n",
            "features.4.conv.0.0.quantize_weight.running_range torch.Size([144, 1, 1, 1])\n",
            "features.4.conv.0.1.weight torch.Size([144])\n",
            "features.4.conv.0.1.bias torch.Size([144])\n",
            "features.4.conv.1.0.weight torch.Size([144, 1, 3, 3])\n",
            "features.4.conv.1.0.equ_scale torch.Size([144, 1, 1, 1])\n",
            "features.4.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.4.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.4.conv.1.0.quantize_weight.running_zero_point torch.Size([144, 1, 1, 1])\n",
            "features.4.conv.1.0.quantize_weight.running_range torch.Size([144, 1, 1, 1])\n",
            "features.4.conv.1.1.weight torch.Size([144])\n",
            "features.4.conv.1.1.bias torch.Size([144])\n",
            "features.4.conv.2.weight torch.Size([32, 144, 1, 1])\n",
            "features.4.conv.2.equ_scale torch.Size([32, 1, 1, 1])\n",
            "features.4.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.4.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.4.conv.2.quantize_weight.running_zero_point torch.Size([32, 1, 1, 1])\n",
            "features.4.conv.2.quantize_weight.running_range torch.Size([32, 1, 1, 1])\n",
            "features.4.conv.3.weight torch.Size([32])\n",
            "features.4.conv.3.bias torch.Size([32])\n",
            "features.5.conv.0.0.weight torch.Size([192, 32, 1, 1])\n",
            "features.5.conv.0.0.equ_scale torch.Size([192, 1, 1, 1])\n",
            "features.5.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.5.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.5.conv.0.0.quantize_weight.running_zero_point torch.Size([192, 1, 1, 1])\n",
            "features.5.conv.0.0.quantize_weight.running_range torch.Size([192, 1, 1, 1])\n",
            "features.5.conv.0.1.weight torch.Size([192])\n",
            "features.5.conv.0.1.bias torch.Size([192])\n",
            "features.5.conv.1.0.weight torch.Size([192, 1, 3, 3])\n",
            "features.5.conv.1.0.equ_scale torch.Size([192, 1, 1, 1])\n",
            "features.5.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.5.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.5.conv.1.0.quantize_weight.running_zero_point torch.Size([192, 1, 1, 1])\n",
            "features.5.conv.1.0.quantize_weight.running_range torch.Size([192, 1, 1, 1])\n",
            "features.5.conv.1.1.weight torch.Size([192])\n",
            "features.5.conv.1.1.bias torch.Size([192])\n",
            "features.5.conv.2.weight torch.Size([32, 192, 1, 1])\n",
            "features.5.conv.2.equ_scale torch.Size([32, 1, 1, 1])\n",
            "features.5.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.5.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.5.conv.2.quantize_weight.running_zero_point torch.Size([32, 1, 1, 1])\n",
            "features.5.conv.2.quantize_weight.running_range torch.Size([32, 1, 1, 1])\n",
            "features.5.conv.3.weight torch.Size([32])\n",
            "features.5.conv.3.bias torch.Size([32])\n",
            "features.6.conv.0.0.weight torch.Size([192, 32, 1, 1])\n",
            "features.6.conv.0.0.equ_scale torch.Size([192, 1, 1, 1])\n",
            "features.6.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.6.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.6.conv.0.0.quantize_weight.running_zero_point torch.Size([192, 1, 1, 1])\n",
            "features.6.conv.0.0.quantize_weight.running_range torch.Size([192, 1, 1, 1])\n",
            "features.6.conv.0.1.weight torch.Size([192])\n",
            "features.6.conv.0.1.bias torch.Size([192])\n",
            "features.6.conv.1.0.weight torch.Size([192, 1, 3, 3])\n",
            "features.6.conv.1.0.equ_scale torch.Size([192, 1, 1, 1])\n",
            "features.6.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.6.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.6.conv.1.0.quantize_weight.running_zero_point torch.Size([192, 1, 1, 1])\n",
            "features.6.conv.1.0.quantize_weight.running_range torch.Size([192, 1, 1, 1])\n",
            "features.6.conv.1.1.weight torch.Size([192])\n",
            "features.6.conv.1.1.bias torch.Size([192])\n",
            "features.6.conv.2.weight torch.Size([32, 192, 1, 1])\n",
            "features.6.conv.2.equ_scale torch.Size([32, 1, 1, 1])\n",
            "features.6.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.6.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.6.conv.2.quantize_weight.running_zero_point torch.Size([32, 1, 1, 1])\n",
            "features.6.conv.2.quantize_weight.running_range torch.Size([32, 1, 1, 1])\n",
            "features.6.conv.3.weight torch.Size([32])\n",
            "features.6.conv.3.bias torch.Size([32])\n",
            "features.7.conv.0.0.weight torch.Size([192, 32, 1, 1])\n",
            "features.7.conv.0.0.equ_scale torch.Size([192, 1, 1, 1])\n",
            "features.7.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.7.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.7.conv.0.0.quantize_weight.running_zero_point torch.Size([192, 1, 1, 1])\n",
            "features.7.conv.0.0.quantize_weight.running_range torch.Size([192, 1, 1, 1])\n",
            "features.7.conv.0.1.weight torch.Size([192])\n",
            "features.7.conv.0.1.bias torch.Size([192])\n",
            "features.7.conv.1.0.weight torch.Size([192, 1, 3, 3])\n",
            "features.7.conv.1.0.equ_scale torch.Size([192, 1, 1, 1])\n",
            "features.7.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.7.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.7.conv.1.0.quantize_weight.running_zero_point torch.Size([192, 1, 1, 1])\n",
            "features.7.conv.1.0.quantize_weight.running_range torch.Size([192, 1, 1, 1])\n",
            "features.7.conv.1.1.weight torch.Size([192])\n",
            "features.7.conv.1.1.bias torch.Size([192])\n",
            "features.7.conv.2.weight torch.Size([64, 192, 1, 1])\n",
            "features.7.conv.2.equ_scale torch.Size([64, 1, 1, 1])\n",
            "features.7.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.7.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.7.conv.2.quantize_weight.running_zero_point torch.Size([64, 1, 1, 1])\n",
            "features.7.conv.2.quantize_weight.running_range torch.Size([64, 1, 1, 1])\n",
            "features.7.conv.3.weight torch.Size([64])\n",
            "features.7.conv.3.bias torch.Size([64])\n",
            "features.8.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
            "features.8.conv.0.0.equ_scale torch.Size([384, 1, 1, 1])\n",
            "features.8.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.8.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.8.conv.0.0.quantize_weight.running_zero_point torch.Size([384, 1, 1, 1])\n",
            "features.8.conv.0.0.quantize_weight.running_range torch.Size([384, 1, 1, 1])\n",
            "features.8.conv.0.1.weight torch.Size([384])\n",
            "features.8.conv.0.1.bias torch.Size([384])\n",
            "features.8.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
            "features.8.conv.1.0.equ_scale torch.Size([384, 1, 1, 1])\n",
            "features.8.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.8.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.8.conv.1.0.quantize_weight.running_zero_point torch.Size([384, 1, 1, 1])\n",
            "features.8.conv.1.0.quantize_weight.running_range torch.Size([384, 1, 1, 1])\n",
            "features.8.conv.1.1.weight torch.Size([384])\n",
            "features.8.conv.1.1.bias torch.Size([384])\n",
            "features.8.conv.2.weight torch.Size([64, 384, 1, 1])\n",
            "features.8.conv.2.equ_scale torch.Size([64, 1, 1, 1])\n",
            "features.8.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.8.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.8.conv.2.quantize_weight.running_zero_point torch.Size([64, 1, 1, 1])\n",
            "features.8.conv.2.quantize_weight.running_range torch.Size([64, 1, 1, 1])\n",
            "features.8.conv.3.weight torch.Size([64])\n",
            "features.8.conv.3.bias torch.Size([64])\n",
            "features.9.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
            "features.9.conv.0.0.equ_scale torch.Size([384, 1, 1, 1])\n",
            "features.9.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.9.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.9.conv.0.0.quantize_weight.running_zero_point torch.Size([384, 1, 1, 1])\n",
            "features.9.conv.0.0.quantize_weight.running_range torch.Size([384, 1, 1, 1])\n",
            "features.9.conv.0.1.weight torch.Size([384])\n",
            "features.9.conv.0.1.bias torch.Size([384])\n",
            "features.9.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
            "features.9.conv.1.0.equ_scale torch.Size([384, 1, 1, 1])\n",
            "features.9.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.9.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.9.conv.1.0.quantize_weight.running_zero_point torch.Size([384, 1, 1, 1])\n",
            "features.9.conv.1.0.quantize_weight.running_range torch.Size([384, 1, 1, 1])\n",
            "features.9.conv.1.1.weight torch.Size([384])\n",
            "features.9.conv.1.1.bias torch.Size([384])\n",
            "features.9.conv.2.weight torch.Size([64, 384, 1, 1])\n",
            "features.9.conv.2.equ_scale torch.Size([64, 1, 1, 1])\n",
            "features.9.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.9.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.9.conv.2.quantize_weight.running_zero_point torch.Size([64, 1, 1, 1])\n",
            "features.9.conv.2.quantize_weight.running_range torch.Size([64, 1, 1, 1])\n",
            "features.9.conv.3.weight torch.Size([64])\n",
            "features.9.conv.3.bias torch.Size([64])\n",
            "features.10.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
            "features.10.conv.0.0.equ_scale torch.Size([384, 1, 1, 1])\n",
            "features.10.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.10.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.10.conv.0.0.quantize_weight.running_zero_point torch.Size([384, 1, 1, 1])\n",
            "features.10.conv.0.0.quantize_weight.running_range torch.Size([384, 1, 1, 1])\n",
            "features.10.conv.0.1.weight torch.Size([384])\n",
            "features.10.conv.0.1.bias torch.Size([384])\n",
            "features.10.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
            "features.10.conv.1.0.equ_scale torch.Size([384, 1, 1, 1])\n",
            "features.10.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.10.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.10.conv.1.0.quantize_weight.running_zero_point torch.Size([384, 1, 1, 1])\n",
            "features.10.conv.1.0.quantize_weight.running_range torch.Size([384, 1, 1, 1])\n",
            "features.10.conv.1.1.weight torch.Size([384])\n",
            "features.10.conv.1.1.bias torch.Size([384])\n",
            "features.10.conv.2.weight torch.Size([64, 384, 1, 1])\n",
            "features.10.conv.2.equ_scale torch.Size([64, 1, 1, 1])\n",
            "features.10.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.10.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.10.conv.2.quantize_weight.running_zero_point torch.Size([64, 1, 1, 1])\n",
            "features.10.conv.2.quantize_weight.running_range torch.Size([64, 1, 1, 1])\n",
            "features.10.conv.3.weight torch.Size([64])\n",
            "features.10.conv.3.bias torch.Size([64])\n",
            "features.11.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
            "features.11.conv.0.0.equ_scale torch.Size([384, 1, 1, 1])\n",
            "features.11.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.11.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.11.conv.0.0.quantize_weight.running_zero_point torch.Size([384, 1, 1, 1])\n",
            "features.11.conv.0.0.quantize_weight.running_range torch.Size([384, 1, 1, 1])\n",
            "features.11.conv.0.1.weight torch.Size([384])\n",
            "features.11.conv.0.1.bias torch.Size([384])\n",
            "features.11.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
            "features.11.conv.1.0.equ_scale torch.Size([384, 1, 1, 1])\n",
            "features.11.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.11.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.11.conv.1.0.quantize_weight.running_zero_point torch.Size([384, 1, 1, 1])\n",
            "features.11.conv.1.0.quantize_weight.running_range torch.Size([384, 1, 1, 1])\n",
            "features.11.conv.1.1.weight torch.Size([384])\n",
            "features.11.conv.1.1.bias torch.Size([384])\n",
            "features.11.conv.2.weight torch.Size([96, 384, 1, 1])\n",
            "features.11.conv.2.equ_scale torch.Size([96, 1, 1, 1])\n",
            "features.11.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.11.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.11.conv.2.quantize_weight.running_zero_point torch.Size([96, 1, 1, 1])\n",
            "features.11.conv.2.quantize_weight.running_range torch.Size([96, 1, 1, 1])\n",
            "features.11.conv.3.weight torch.Size([96])\n",
            "features.11.conv.3.bias torch.Size([96])\n",
            "features.12.conv.0.0.weight torch.Size([576, 96, 1, 1])\n",
            "features.12.conv.0.0.equ_scale torch.Size([576, 1, 1, 1])\n",
            "features.12.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.12.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.12.conv.0.0.quantize_weight.running_zero_point torch.Size([576, 1, 1, 1])\n",
            "features.12.conv.0.0.quantize_weight.running_range torch.Size([576, 1, 1, 1])\n",
            "features.12.conv.0.1.weight torch.Size([576])\n",
            "features.12.conv.0.1.bias torch.Size([576])\n",
            "features.12.conv.1.0.weight torch.Size([576, 1, 3, 3])\n",
            "features.12.conv.1.0.equ_scale torch.Size([576, 1, 1, 1])\n",
            "features.12.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.12.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.12.conv.1.0.quantize_weight.running_zero_point torch.Size([576, 1, 1, 1])\n",
            "features.12.conv.1.0.quantize_weight.running_range torch.Size([576, 1, 1, 1])\n",
            "features.12.conv.1.1.weight torch.Size([576])\n",
            "features.12.conv.1.1.bias torch.Size([576])\n",
            "features.12.conv.2.weight torch.Size([96, 576, 1, 1])\n",
            "features.12.conv.2.equ_scale torch.Size([96, 1, 1, 1])\n",
            "features.12.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.12.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.12.conv.2.quantize_weight.running_zero_point torch.Size([96, 1, 1, 1])\n",
            "features.12.conv.2.quantize_weight.running_range torch.Size([96, 1, 1, 1])\n",
            "features.12.conv.3.weight torch.Size([96])\n",
            "features.12.conv.3.bias torch.Size([96])\n",
            "features.13.conv.0.0.weight torch.Size([576, 96, 1, 1])\n",
            "features.13.conv.0.0.equ_scale torch.Size([576, 1, 1, 1])\n",
            "features.13.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.13.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.13.conv.0.0.quantize_weight.running_zero_point torch.Size([576, 1, 1, 1])\n",
            "features.13.conv.0.0.quantize_weight.running_range torch.Size([576, 1, 1, 1])\n",
            "features.13.conv.0.1.weight torch.Size([576])\n",
            "features.13.conv.0.1.bias torch.Size([576])\n",
            "features.13.conv.1.0.weight torch.Size([576, 1, 3, 3])\n",
            "features.13.conv.1.0.equ_scale torch.Size([576, 1, 1, 1])\n",
            "features.13.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.13.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.13.conv.1.0.quantize_weight.running_zero_point torch.Size([576, 1, 1, 1])\n",
            "features.13.conv.1.0.quantize_weight.running_range torch.Size([576, 1, 1, 1])\n",
            "features.13.conv.1.1.weight torch.Size([576])\n",
            "features.13.conv.1.1.bias torch.Size([576])\n",
            "features.13.conv.2.weight torch.Size([96, 576, 1, 1])\n",
            "features.13.conv.2.equ_scale torch.Size([96, 1, 1, 1])\n",
            "features.13.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.13.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.13.conv.2.quantize_weight.running_zero_point torch.Size([96, 1, 1, 1])\n",
            "features.13.conv.2.quantize_weight.running_range torch.Size([96, 1, 1, 1])\n",
            "features.13.conv.3.weight torch.Size([96])\n",
            "features.13.conv.3.bias torch.Size([96])\n",
            "features.14.conv.0.0.weight torch.Size([576, 96, 1, 1])\n",
            "features.14.conv.0.0.equ_scale torch.Size([576, 1, 1, 1])\n",
            "features.14.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.14.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.14.conv.0.0.quantize_weight.running_zero_point torch.Size([576, 1, 1, 1])\n",
            "features.14.conv.0.0.quantize_weight.running_range torch.Size([576, 1, 1, 1])\n",
            "features.14.conv.0.1.weight torch.Size([576])\n",
            "features.14.conv.0.1.bias torch.Size([576])\n",
            "features.14.conv.1.0.weight torch.Size([576, 1, 3, 3])\n",
            "features.14.conv.1.0.equ_scale torch.Size([576, 1, 1, 1])\n",
            "features.14.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.14.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.14.conv.1.0.quantize_weight.running_zero_point torch.Size([576, 1, 1, 1])\n",
            "features.14.conv.1.0.quantize_weight.running_range torch.Size([576, 1, 1, 1])\n",
            "features.14.conv.1.1.weight torch.Size([576])\n",
            "features.14.conv.1.1.bias torch.Size([576])\n",
            "features.14.conv.2.weight torch.Size([160, 576, 1, 1])\n",
            "features.14.conv.2.equ_scale torch.Size([160, 1, 1, 1])\n",
            "features.14.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.14.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.14.conv.2.quantize_weight.running_zero_point torch.Size([160, 1, 1, 1])\n",
            "features.14.conv.2.quantize_weight.running_range torch.Size([160, 1, 1, 1])\n",
            "features.14.conv.3.weight torch.Size([160])\n",
            "features.14.conv.3.bias torch.Size([160])\n",
            "features.15.conv.0.0.weight torch.Size([960, 160, 1, 1])\n",
            "features.15.conv.0.0.equ_scale torch.Size([960, 1, 1, 1])\n",
            "features.15.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.15.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.15.conv.0.0.quantize_weight.running_zero_point torch.Size([960, 1, 1, 1])\n",
            "features.15.conv.0.0.quantize_weight.running_range torch.Size([960, 1, 1, 1])\n",
            "features.15.conv.0.1.weight torch.Size([960])\n",
            "features.15.conv.0.1.bias torch.Size([960])\n",
            "features.15.conv.1.0.weight torch.Size([960, 1, 3, 3])\n",
            "features.15.conv.1.0.equ_scale torch.Size([960, 1, 1, 1])\n",
            "features.15.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.15.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.15.conv.1.0.quantize_weight.running_zero_point torch.Size([960, 1, 1, 1])\n",
            "features.15.conv.1.0.quantize_weight.running_range torch.Size([960, 1, 1, 1])\n",
            "features.15.conv.1.1.weight torch.Size([960])\n",
            "features.15.conv.1.1.bias torch.Size([960])\n",
            "features.15.conv.2.weight torch.Size([160, 960, 1, 1])\n",
            "features.15.conv.2.equ_scale torch.Size([160, 1, 1, 1])\n",
            "features.15.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.15.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.15.conv.2.quantize_weight.running_zero_point torch.Size([160, 1, 1, 1])\n",
            "features.15.conv.2.quantize_weight.running_range torch.Size([160, 1, 1, 1])\n",
            "features.15.conv.3.weight torch.Size([160])\n",
            "features.15.conv.3.bias torch.Size([160])\n",
            "features.16.conv.0.0.weight torch.Size([960, 160, 1, 1])\n",
            "features.16.conv.0.0.equ_scale torch.Size([960, 1, 1, 1])\n",
            "features.16.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.16.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.16.conv.0.0.quantize_weight.running_zero_point torch.Size([960, 1, 1, 1])\n",
            "features.16.conv.0.0.quantize_weight.running_range torch.Size([960, 1, 1, 1])\n",
            "features.16.conv.0.1.weight torch.Size([960])\n",
            "features.16.conv.0.1.bias torch.Size([960])\n",
            "features.16.conv.1.0.weight torch.Size([960, 1, 3, 3])\n",
            "features.16.conv.1.0.equ_scale torch.Size([960, 1, 1, 1])\n",
            "features.16.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.16.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.16.conv.1.0.quantize_weight.running_zero_point torch.Size([960, 1, 1, 1])\n",
            "features.16.conv.1.0.quantize_weight.running_range torch.Size([960, 1, 1, 1])\n",
            "features.16.conv.1.1.weight torch.Size([960])\n",
            "features.16.conv.1.1.bias torch.Size([960])\n",
            "features.16.conv.2.weight torch.Size([160, 960, 1, 1])\n",
            "features.16.conv.2.equ_scale torch.Size([160, 1, 1, 1])\n",
            "features.16.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.16.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.16.conv.2.quantize_weight.running_zero_point torch.Size([160, 1, 1, 1])\n",
            "features.16.conv.2.quantize_weight.running_range torch.Size([160, 1, 1, 1])\n",
            "features.16.conv.3.weight torch.Size([160])\n",
            "features.16.conv.3.bias torch.Size([160])\n",
            "features.17.conv.0.0.weight torch.Size([960, 160, 1, 1])\n",
            "features.17.conv.0.0.equ_scale torch.Size([960, 1, 1, 1])\n",
            "features.17.conv.0.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.17.conv.0.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.17.conv.0.0.quantize_weight.running_zero_point torch.Size([960, 1, 1, 1])\n",
            "features.17.conv.0.0.quantize_weight.running_range torch.Size([960, 1, 1, 1])\n",
            "features.17.conv.0.1.weight torch.Size([960])\n",
            "features.17.conv.0.1.bias torch.Size([960])\n",
            "features.17.conv.1.0.weight torch.Size([960, 1, 3, 3])\n",
            "features.17.conv.1.0.equ_scale torch.Size([960, 1, 1, 1])\n",
            "features.17.conv.1.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.17.conv.1.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.17.conv.1.0.quantize_weight.running_zero_point torch.Size([960, 1, 1, 1])\n",
            "features.17.conv.1.0.quantize_weight.running_range torch.Size([960, 1, 1, 1])\n",
            "features.17.conv.1.1.weight torch.Size([960])\n",
            "features.17.conv.1.1.bias torch.Size([960])\n",
            "features.17.conv.2.weight torch.Size([320, 960, 1, 1])\n",
            "features.17.conv.2.equ_scale torch.Size([320, 1, 1, 1])\n",
            "features.17.conv.2.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.17.conv.2.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.17.conv.2.quantize_weight.running_zero_point torch.Size([320, 1, 1, 1])\n",
            "features.17.conv.2.quantize_weight.running_range torch.Size([320, 1, 1, 1])\n",
            "features.17.conv.3.weight torch.Size([320])\n",
            "features.17.conv.3.bias torch.Size([320])\n",
            "features.18.0.weight torch.Size([1280, 320, 1, 1])\n",
            "features.18.0.equ_scale torch.Size([1280, 1, 1, 1])\n",
            "features.18.0.quantize_input.running_zero_point torch.Size([1, 1, 1, 1])\n",
            "features.18.0.quantize_input.running_range torch.Size([1, 1, 1, 1])\n",
            "features.18.0.quantize_weight.running_zero_point torch.Size([1280, 1, 1, 1])\n",
            "features.18.0.quantize_weight.running_range torch.Size([1280, 1, 1, 1])\n",
            "features.18.1.weight torch.Size([1280])\n",
            "features.18.1.bias torch.Size([1280])\n",
            "classifier.1.weight torch.Size([10, 1280])\n",
            "classifier.1.bias torch.Size([10])\n",
            "classifier.1.equ_scale torch.Size([10, 1])\n",
            "classifier.1.quantize_input.running_zero_point torch.Size([1])\n",
            "classifier.1.quantize_input.running_range torch.Size([1])\n",
            "classifier.1.quantize_weight.running_zero_point torch.Size([10, 1])\n",
            "classifier.1.quantize_weight.running_range torch.Size([10, 1])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model_xd.named_parameters():\n",
        "    print(name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQceb6IlLcur"
      },
      "outputs": [],
      "source": [
        "model.conv1.name = \"QConv2d\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvFnIQ0PLcus",
        "outputId": "44ce1ac1-b350-4865-9952-fac3afb71875"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'QConv2d'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.conv1.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iFWMsyGLcus",
        "outputId": "8f39b313-c90e-44c2-bc13-010a15212f42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QConv2d(\n",
            "  3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")\n",
            "QConv2d(\n",
            "  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")\n",
            "QConv2d(\n",
            "  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")\n",
            "QConv2d(\n",
            "  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")\n",
            "QConv2d(\n",
            "  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")\n",
            "QConv2d(\n",
            "  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")\n",
            "QConv2d(\n",
            "  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")\n",
            "QConv2d(\n",
            "  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")\n",
            "QConv2d(\n",
            "  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")\n",
            "QConv2d(\n",
            "  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (quantize_input): QuantThUpdate()\n",
            "  (quantize_weight): QuantThUpdate()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "for k, v in cached_input_output.items():\n",
        "    print(k)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDyY_7zZLcut"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
